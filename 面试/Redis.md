# Redis

## 基础

### Redis 有哪些数据类型？

[![三分恶面渣逆袭：Redis基本数据类型](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210042342.png)](https://camo.githubusercontent.com/a243bb851332cd27f1350bbe0d14d05913fa7c322718af1687e7f421c88569ab/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d31303433346463372d633761332d346331612d623438342d6465336662333736363965652e706e67)

### Redis 为什么快呢？

①、**基于内存的数据存储**，Redis 将数据存储在内存当中，使得数据的读写操作避开了磁盘 I/O。而内存的访问速度远超硬盘，这是 Redis 读写速度快的根本原因。

②、**单线程模型**，Redis 使用单线程模型来处理客户端的请求，这意味着在任何时刻只有一个命令在执行。这样就**避免了线程切换和锁竞争带来的消耗**。

③、**IO 多路复用**，**基于 Linux 的 select/epoll 机制**。该机制允许内核中**同时存在多个监听套接字和已连接套接字**，内核会一直监听这些套接字上的连接请求或者数据请求，一旦有请求到达，就会交给 Redis 处理，就实现了所谓的 Redis 单个线程处理多个 IO 读写的请求。

[![三分恶面渣逆袭：Redis使用IO多路复用和自身事件模型](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210046029.png)](https://camo.githubusercontent.com/ef2fd1416ca691a8aa46b3ee59bc6e21ed987eeee71d17d121439121b09d62c7/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d65303562636136312d343630302d343935632d623932612d3235616338323265303334652e706e67)

④、**高效的数据结构**，Redis 提供了多种高效的数据结构，如字符串（String）、列表（List）、集合（Set）、有序集合（Sorted Set）等，这些数据结构经过了高度优化，能够支持快速的数据操作。



### 能说一下 I/O 多路复用吗？

IO 多路复用是一种高效管理多个 IO 事件的技术，通过**单线程监控多个文件描述符**（fd），实现高并发的 IO 操作。

常见的 I/O 多路复用机制包括 select、poll 和 epoll 等。

| 特性           | `select`             | `poll`         | `epoll`              |
| -------------- | -------------------- | -------------- | -------------------- |
| 文件描述符限制 | 受 `FD_SETSIZE` 限制 | 无限制         | 无限制               |
| 时间复杂度     | O(n)                 | O(n)           | O(1)                 |
| 数据复制       | 需要                 | 需要           | 不需要               |
| 工作方式       | 线性扫描             | 线性扫描       | 事件通知             |
| 内核支持       | 所有 UNIX 系统       | 所有 UNIX 系统 | Linux 2.6 及以上版本 |
| 适用场景       | 少量连接             | 中等连接       | 大量并发连接         |

同学小王举手，你就让小王回答；小李举手，你就让小李回答；小张举手，你就让小张回答。

这种模式就是 IO 多路复用，你只需要在讲台上等，谁举手谁回答，不需要一个一个去问。



整个过程只在进行 select、poll、epoll 这些调用的时候才会阻塞，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的 **reactor 模式**。

**Redis 就是使用 epoll** 这样的 I/O 多路复用机制，在单线程模型下实现高效的网络 I/O，从而支持高并发的请求处理。



#### 举例子说一下 I/O 多路复用？

- 第一种选择：按顺序逐个检查，先检查 A，然后是 B，之后是 C、D。。。这中间如果有一个学生卡住，全班都会被耽误。这种模式就好比，你用循环挨个处理 socket，根本不具有并发能力。
- 第二种选择：你创建 30 个分身，每个分身检查一个学生的答案是否正确。 这种类似于为每一个用户创建一个进程或者线程处理连接。
- 第三种选择，你站在讲台上等，谁解答完谁举手。这时 C、D 举手，表示他们解答问题完毕，你下去依次检查 C、D 的答案，然后继续回到讲台上等。此时 E、A 又举手，然后去处理 E 和 A。

第一种就是阻塞 IO 模型，第三种就是 I/O 复用模型。





### Redis 为什么早期选择单线程？

因为 Redis 是基于内存的操作，CPU 成为 Redis 的瓶颈的情况很少见，Redis 的瓶颈最有可能是**内存的大小或者网络限制。**

如果想要最大程度利用 CPU，可以在一台机器上启动**多个 Redis 实例**。



### Redis6.0 使用多线程是怎么回事?

Redis6.0 的多线程是用多线程来处理数据的**读写和协议解析**，但是 Redis**执行命令**还是单线程的。

这样做的目的是因为 Redis 的性能瓶颈在于网络 IO 而非 CPU，使用**多线程能提升 IO 读写的效率**，从而整体提高 Redis 的性能。





### 说说 Redis 常用命令

①、操作字符串的命令有：

- `SET key value`：设置键 key 的值为 value。
- `GET key`：获取键 key 的值。
- `DEL key`：删除键 key。
- `INCR key`：将键 key 存储的数值增一。
- `DECR key`：将键 key 存储的数值减一。

②、操作列表的命令有：

- `LPUSH key value`：将一个值插入到列表 key 的头部。
- `RPUSH key value`：将一个值插入到列表 key 的尾部。
- `LPOP key`：移除并返回列表 key 的头元素。
- `RPOP key`：移除并返回列表 key 的尾元素。
- `LRANGE key start stop`：获取列表 key 中指定范围内的元素。

③、操作集合的命令有：

- `SADD key member`：向集合 key 添加一个元素。
- `SREM key member`：从集合 key 中移除一个元素。
- `SMEMBERS key`：返回集合 key 中的所有元素。

④、操作有序集合的命令有：

- `ZADD key score member`：向有序集合 key 添加一个成员，或更新其分数。
- `ZRANGE key start stop [WITHSCORES]`：按照索引区间返回有序集合 key 中的成员，可选 WITHSCORES 参数返回分数。
- `ZREVRANGE key start stop [WITHSCORES]`：返回有序集合 key 中，指定区间内的成员，按分数递减。
- `ZREM key member`：移除有序集合 key 中的一个或多个成员。

⑤、操作哈希的命令有：

- `HSET key field value`：向键为 key 的哈希表中设置字段 field 的值为 value。
- `HGET key field`：获取键为 key 的哈希表中字段 field 的值。
- `HGETALL key`：获取键为 key 的哈希表中所有的字段和值。
- `HDEL key field`：删除键为 key 的哈希表中的一个或多个字段。



#### 详细说说 set 命令？

在 Redis 中，设置键值对的命令是 set。set 命令有几个常用的参数：

①、可以通过 EX 或 PX 为键设置过期时间（秒或毫秒）

```sh
redis-cli SET session_id "xyz" EX 3600  # 设置键 session_id，值为 "xyz"，过期时间为 3600 秒
```

②、NX 选项表示只有键不存在时才设置

```sh
redis-cli SET lock_key "locked" NX
```

③、XX 选项表示只有键存在时才设置

```sh
redis-cli SET config "new_config" XX
```



#### sadd 命令的时间复杂度是多少？

向指定 Set 中添加 1 个或多个 member，如果指定 Set 不存在，会自动创建一个。**时间复杂度 O(N)** ，N 为添加的 member 个数。



### 单线程 Redis 的 QPS 是多少？

一个普通服务器的 Redis 实例通常可以达到每秒数万到几十万的 QPS。





## 持久化

### Redis 持久化方式有哪些？有什么区别？

**RDB 持久化和 AOF持久化**。这两种方式可以单独使用，也可以同时使用。

#### 说一下 RDB？

RDB 持久化通过**创建数据集的快照**来工作，在指定的时间间隔内将 Redis 在某一时刻的数据状态保存到磁盘的一个 RDB 文件中。

可通过 save 和 bgsave 命令两个命令来手动触发 RDB 持久化操作：

[![三分恶面渣逆袭：save和bgsave](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210109708.png)](https://camo.githubusercontent.com/07c0751c5cf77ab0455e4ef92d62f656122aaca42239d16ee9a5ab3c9dfba898/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d66666535366533322d333463352d343533642d383835392d6332666562626536613033382e706e67)

**①、save 命令**：会同步地将 Redis 的所有数据保存到磁盘上的一个 RDB 文件中。这个操作会**阻塞所有客户端**请求直到 RDB 文件被完全写入磁盘。

当 Redis 数据集较大时，使用 SAVE 命令会导致 Redis 服务器停止响应客户端的请求。

不推荐在生产环境中使用，除非数据集非常小，或者可以接受服务暂时的不可用状态。

**②、bgsave 命令**：会在**后台异步地创建 Redis 的数据快照**，并将快照保存到磁盘上的 RDB 文件中。这个命令会立即返回，Redis 服务器可以继续处理客户端请求。

在 BGSAVE 命令执行期间，Redis 会继续响应客户端的请求，对服务的可用性影响较小。快照的创建过程是由一个子进程完成的，主进程不会被阻塞。是在生产环境中执行 RDB 持久化的推荐方式。



#### 以下场景会自动触发 RDB 持久化：

①、在 Redis 配置文件（通常是 redis.conf）中，可以通过`save <seconds> <changes>`指令配置自动触发 RDB 持久化的条件。这个指令可以设置多次，每个设置定义了一个时间间隔（秒）和该时间内发生的变更次数阈值。

```sh
如果至少有 10 个键被修改，300 秒后自动触发一次 RDB 持久化。
save 300 10
```

②、当 Redis 服务器通过 **SHUTDOWN 命令正常关闭**时，如果没有禁用 RDB 持久化，Redis 会自动执行一次 RDB 持久化，以确保数据在下次启动时能够恢复。

③、在 Redis 复制场景中，当一个 Redis 实例**被配置为从节点并且与主节点建立连接时**，它可能会根据配置接收主节点的 RDB 文件来初始化数据集。这个过程中，主节点会在后台自动触发 RDB 持久化，然后将生成的 RDB 文件发送给从节点。



#### 说一下 AOF？

AOF 持久化通过记录每个写操作命令并将其追加到 AOF 文件中来工作，恢复时通过重新执行这些命令来重建数据集。

AOF 的主要作用是解决了数据持久化的实时性，目前已经是 Redis 持久化的主流方式。

AOF 的工作流程操作有四个步骤：**命令写入、文件同步、文件重写、重启加载**。

[![三分恶面渣逆袭：AOF工作流程](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210113258.png)](https://camo.githubusercontent.com/057a43e31d03ffa9a9eebd8b4be021db12c6f6ddec9dd26bde7cff6945392aad/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d61396662363230322d623161312d343834642d613466612d6665663531393039306234342e706e67)

1）当 AOF 持久化功能被启用时（通过在配置文件中设置 appendonly 参数为 yes 来启用），Redis 服务器会将接收到的所有**写命令**（比如 SET, LPUSH, SADD 等修改数据的命令）追加到 AOF 缓冲区（buffer）的末尾。

2）为了将缓冲区中的命令持久化到磁盘中的 AOF 文件，Redis 提供了几种不同的同步策略：

- **always**：**每次**写命令都会同步到 AOF 文件，这提供了最高的数据安全性，但可能因为磁盘 I/O 的延迟而影响性能。
- **everysec**（默认）：**每秒同步一次**，这是一种折衷方案，提供了较好的性能和数据安全性。如果系统崩溃，最多可能丢失最后一秒的数据。
- **no**：只会在 AOF 关闭或 Redis **关闭时执行**， 或由操作系统内核触发。在这种模式下，如果发生宕机，那么丢失的数据量由操作系统内核的缓存冲洗策略决定。

3）随着操作的不断执行，AOF 文件会不断增长，为了**减小 AOF 文件大小**，Redis 可以重写 AOF 文件：

- 重写过程不会解析原始的 AOF 文件，而是将当前内存中的数据库状态转换为一系列写命令，然后保存到一个**新的 AOF 文件**中。
- AOF 重写操作由 BGREWRITEAOF 命令触发，它会创建一个子进程来执行重写操作，因此不会阻塞主进程。
- 重写过程中，新的写命令会继续追加到旧的 AOF 文件中，同时也会被记录到一个缓冲区中。一旦重写完成，Redis 会将这个缓冲区中的命令追加到新的 AOF 文件中，然后切换到新的 AOF 文件上，以确保数据的完整性。

4）当 Redis 服务器启动时，如果配置为使用 AOF 持久化方式，它会读取 AOF 文件中的所有命令并重新执行它们，以恢复数据库的状态。



#### AOF 文件存储的是什么类型的数据？

AOF 文件存储的是 Redis 所有的**写操作**命令，比如 SET、HSET、INCR 等。



### RDB 和 AOF 各自有什么优缺点？

RDB 是一个非常紧凑的单文件（**二进制文件 dump.rdb**），代表了 Redis 在某个时间点上的数据快照。非常适合用于**备份数据**，比如在夜间进行备份，然后将 RDB 文件复制到远程服务器。但可能会丢失最后一次持久化后的数据。

AOF 的最大优点是**灵活，实时性好**，可以设置不同的 fsync 策略，如每秒同步一次，每次写入命令就同步，或者完全由操作系统来决定何时同步。但 AOF 文件往往**比较大，恢复速度慢**，因为它记录了每个写操作。



### RDB 和 AOF 如何选择？

如果需要**尽可能减少数据丢失，AOF 是更好的选择**。尤其是在频繁写入的环境下，设置 AOF 每秒同步可以最大限度减少数据丢失。

如果**性能是首要考虑，RDB 可能更适合**。RDB 的快照生成通常对性能影响较小，并且数据恢复速度快。

如果系统需要经常重启，并且希望系统重启后快速恢复，RDB 可能是更好的选择。虽然 AOF 也提供了良好的恢复能力，但重写 AOF 文件可能会比较慢。

在许多生产环境中，同时启用 RDB 和 AOF 被认为是最佳实践：

- **使用 RDB 进行快照备份。**
- **使用 AOF 保证崩溃后的最大数据完整性。**



### Redis 的数据恢复？

![三分恶面渣逆袭：Redis启动加载数据](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210120486.png)



### Redis 4.0 的混合持久化了解吗？

在 Redis 4.0 版本中，混合持久化模式会在 **AOF 重写的时候同时生成一份 RDB 快照，然后将这份快照作为 AOF 文件的一部分，最后再附加新的写入命令**。

[![三分恶面渣逆袭：混合持久化](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210121337.png)](https://camo.githubusercontent.com/9e29307632ddd230b1dfa700b25c7d1e1660c5eaa4bfecc9d95c3fd34c702006/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d31396335333165352d646139352d343935612d613463342d6436336130623862626139352e706e67)

当需要恢复数据时，**Redis 先加载 RDB 文件来恢复到快照时刻的状态，然后应用 RDB 之后记录的 AOF 命令来恢复之后的数据更改**



#### 如何设置持久化模式？

可以通过编辑 Redis 的配置文件 redis.conf 来进行设置，或者在运行时通过 Redis 命令行动态调整。

RDB 持久化通过在配置文件中设置快照（snapshotting）规则来启用。这些规则定义了在多少秒内如果有多少个键被修改，则自动执行一次持久化操作。

```sh
save 900 1      # 如果至少有1个键被修改，900秒后自动保存一次
save 300 10     # 如果至少有10个键被修改，300秒后自动保存一次
save 60 10000   # 如果至少有10000个键被修改，60秒后自动保存一次
```

AOF 持久化是通过在配置文件中设置 appendonly 参数为 yes 来启用的：

```
appendonly yes
```

此外，还可以配置 AOF 文件的写入频率，这是通过 appendfsync 设置的：

```sh
appendfsync always    # 每次写入数据都同步，保证数据不丢失，但性能较低
appendfsync everysec  # 每秒同步一次，折衷方案
appendfsync no        # 由操作系统决定何时同步，性能最好，但数据安全性最低
```

为了优化 AOF 文件的大小，Redis 允许自动或手动重写 AOF 文件。可以在配置文件中设置重写的触发条件：

```sh
auto-aof-rewrite-percentage 100  # 增长到原大小的100%时触发重写
auto-aof-rewrite-min-size 64mb   # AOF 文件至少达到64MB时才考虑重写
```

手动执行 AOF 重写的命令是：

```sh
redis-cli bgrewriteaof
```





## 高可用

**主从复制、哨兵模式和集群模式**

### 主从复制了解吗？

主从复制（Master-Slave Replication）是指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器。

前者称为主节点（master），后者称为从节点（slave）。且数据的复制是单向的，只能由主节点到从节点。

![三分恶面渣逆袭：Redis主从复制简图](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210124189.png)

在 Redis 主从架构中，主节点负责处理所有的写操作，并将这些操作异步复制到从节点。从节点主要用于读取操作，以分担主节点的压力和提高读性能。

#### 主从复制主要的作用是什么?

①、**数据冗余：** 主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。

②、**故障恢复：** 如果主节点挂掉了，可以将一个从节点提升为主节点，从而实现故障的快速恢复。

③、**负载均衡：** 在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务 *（即写 Redis 时连接主节点，读 Redis 时连接从节点）*，分担服务器负载。尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高 Redis 服务器的并发量。

④、**高可用基石：** 除了上述作用以外，主从复制还是哨兵和集群能够实施的 **基础**。



#### 主从复制出现数据不一致怎么办？

Redis 的主从复制是异步进行的，这意味着主节点在执行完写操作后，会立即返回给客户端，而不是等待从节点完成数据同步。

为了解决数据不一致的问题，应该尽量保证主从节点之间的**网络连接状况良好**，比如说避免在不同机房之间部署主从节点，以减少网络延迟。但可能会带来新的问题，就是整个机房都挂掉的情况。

此外，Redis 本身也提供了一些机制来解决数据不一致的问题，比如说通过 Redis 的 `INFO replication` 命令监控主从节点的复制进度，及时发现和处理复制延迟。

具体做法是获取主节点的 **master_repl_offset** 和从节点的 **slave_repl_offset**，计算两者的差值。如果差值超过预设的阈值，采取措施（如停止从节点的数据读取）以减少读到不一致数据的情况。



#### Redis解决单点故障主要靠什么？

主从复制，当主节点发生故障时，可以通过手动或自动方式将某个从节点提升为新的主节点，继续对外提供服务，从而避免单点故障。

Redis 的哨兵机制（Sentinel）可以实现自动化的故障转移，当主节点宕机时，哨兵会自动将一个从节点升级为新的主节点。

另外，集群模式下，当某个节点发生故障时，Redis Cluster 会自动将请求路由到其他节点，并通过从节点进行故障恢复。





### Redis 主从有几种常见的拓扑结构？

1. 一主一从结构
2. 一主多从结构（又称为星形拓扑结构）

3. 树状主从结构（又称为树状拓扑结构）






### Redis 的主从复制原理了解吗？

 [![Redis主从复制工作流程](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210749800.png)](https://camo.githubusercontent.com/864a3254788003e5b3f75ff5de24a57389d9a1dd26be312c4e7fde87f0d647a7/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d32313132336231652d363862342d343336622d616338342d3333363561343961383162642e706e67)

1. 保存主节点（master）信息 这一步只是保存主节点信息，**保存主节点的 ip 和 port**。
2. 主从建立连接 从节点（slave）发现新的主节点后，会**尝试和主节点建立网络连接**。
3. **发送 ping 命令** 连接建立成功后从节点发送 ping 请求进行首次通信，主要是检测主从之间网络套接字是否可用、主节点当前是否可接受处理命令。
4. **权限验证** 如果主节点要求密码验证，从节点必须正确的密码才能通过验证。
5. **同步数据集** 主从复制连接正常通信后，主节点会把持有的数据全部发送给从节点。
6. **命令持续复制** 接下来主节点会持续地把写命令发送给从节点，保证主从数据一致性。



### 说说主从数据同步的方式？

Redis 在 2.8 及以上版本使用 psync 命令完成主从数据同步，同步过程分为：**全量复制和部分复制**。

[![主从数据同步方式](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210751127.png)](https://camo.githubusercontent.com/f6a9780d8f0f53b3c2dd567c2867f36aa18ed4633e0a3515699ce105c3b3ba77/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d37353138663731352d366465652d346537302d623937322d3861656439383739653435312e706e67)

**全量复制** 一般用于初次复制场景，Redis 早期支持的复制功能只有全量复制，它会把主节点全部数据一次性发送给从节点，当数据量较大时，会对主从节点和网络造成很大的开销。

全量复制的完整运行流程如下： 

[![全量复制](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210751807.png)](https://camo.githubusercontent.com/d3439a9ecc58e652e90c2e91c1d640b9d385e20fbdcd17136656fa11c7eb6ecf/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d61613864323936302d623334312d343963632d623034632d3230313234316664313564652e706e67)

1. 发送 psync 命令进行数据同步，由于是第一次进行复制，从节点没有复制偏移量和主节点的运行 ID，所以发送 psync-1。
2. 主节点根据 psync-1 解析出当前为全量复制，回复+FULLRESYNC 响应。
3. 从节点接收主节点的响应数据保存运行 ID 和偏移量 offset
4. 主节点执行 bgsave 保存 RDB 文件到本地
5. 主节点发送 RDB 文件给从节点，从节点把接收的 RDB 文件保存在本地并直接作为从节点的数据文件
6. 对于从节点开始接收 RDB 快照到接收完成期间，主节点仍然响应读写命令，因此主节点会把这期间写命令数据保存在复制客户端缓冲区内，当从节点加载完 RDB 文件后，主节点再把缓冲区内的数据发送给从节点，保证主从之间数据一致性。
7. 从节点接收完主节点传送来的全部数据后会清空自身旧数据
8. 从节点清空数据后开始加载 RDB 文件
9. 从节点成功加载完 RDB 后，如果当前节点开启了 AOF 持久化功能， 它会立刻做 bgrewriteaof 操作，为了保证全量复制后 AOF 持久化文件立刻可用。

**部分复制** 部分复制主要是 Redis 针对全量复制的过高开销做出的一种优化措施， 使用 psync{runId}{offset}命令实现。当从节点（slave）正在复制主节点 （master）时，如果出现网络闪断或者命令丢失等异常情况时，从节点会向 主节点要求补发丢失的命令数据，如果主节点的复制积压缓冲区内存在这部分数据则直接发送给从节点，这样就可以保持主从节点复制的一致性。 [![部分复制](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210751301.png)](https://camo.githubusercontent.com/5c73c44b4db854de1136a5ead3262eef763e388b244da6eec0034823a377e222/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d38373630306337322d636336612d343635362d383162322d6537313836346339376632332e706e67)

1. 当主从节点之间网络出现中断时，如果超过 repl-timeout 时间，主节点会认为从节点故障并中断复制连接
2. 主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内部存在的复制积压缓冲区，依然可以保存最近一段时间的写命令数据，默认最大缓存 1MB。
3. 当主从节点网络恢复后，从节点会再次连上主节点
4. 当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行 ID。因此会把它们当作 psync 参数发送给主节点，要求进行部分复制操作。
5. 主节点接到 psync 命令后首先核对参数 runId 是否与自身一致，如果一 致，说明之前复制的是当前主节点；之后根据参数 offset 在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送+CONTINUE 响应，表示可以进行部分复制。
6. 主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。



### 主从复制存在哪些问题呢？

主从复制虽好，但也存在一些问题：

- 一旦主节点出现故障，需要手动将一个从节点晋升为主节点，同时需要修改应用方的主节点地址，还需要命令其他从节点去复制新的主节点，整个过程都需要人工干预。
- 主节点的**写能力受到单机的限制**。
- 主节点的**存储能力受到单机的限制**。

第一个问题是 Redis 的高可用问题，第二、三个问题属于 Redis 的分布式问题。





### Redis 哨兵了解吗？

[![三分恶面渣逆袭：Redis Sentinel](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210754758.png)](https://camo.githubusercontent.com/e2c8c04ac9d8c6ab32633eedeae45d2a155556adcb37d4796163a1e58d09314a/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d38623161303535632d663037372d343966662d393433322d6331393464346663333633392e706e67)

### Redis 哨兵实现原理知道吗？

哨兵的工作流程包括定时监控、主观下线和客观下线、领导者 Sentinel 节点选举、故障转移等。

![image-20241221075510419](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210755507.png)

每个 Sentinel 实例会定期通过 PING 命令向主节点和从节点发送心跳包。

[![三分恶面渣逆袭：三个定时任务](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210754569.png)](https://camo.githubusercontent.com/b2277406e8b886c469a0ac1d83eff6f15ca9d0a4987de7c3da47c7824ecdf186/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d65373730386638642d656633342d343235352d623564302d6362333030633634393731362e706e67)

如果一个节点长时间没有响应 PING 命令，Sentinel 会将该节点标记为**主观下线**。当多个 Sentinel 同时认为一个节点不可用时，该节点被标记为**客观下线**。

[![三分恶面渣逆袭：主观下线和客观下线](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210754283.png)](https://camo.githubusercontent.com/914c210948cef9bdaaa5567ae9d19cf2cd0fc37a039e42e0fc9dc7c15f279437/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d31313833396132342d393234392d343861352d386339642d3838386161383064393164632e706e67)

当主节点被确认下线后，Sentinel 之间会通过**类似 Raft 的选举算法**进行协商，选出一个领导者 Sentinel 来负责执行故障转移。

![](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210755381.png)

1. 将某个从节点提升为新的主节点。
2. 通知其他从节点重新复制新的主节点的数据。





### 领导者 Sentinel 节点选举了解吗？

Redis 使用 Raft 算法实现领导者选举的：当主节点挂掉后，新的主节点是由剩余的从节点发起选举后晋升的。

[![二哥的 Java 进阶之路：领导者Sentinel节点选举](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210757448.png)](https://camo.githubusercontent.com/b47da26aa5791d1d2c452fa8299ab702ab60c46ca85acc10df4bb8e636d1592c/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f73747574796d6f72652f72656469732d32303234303831393131323731322e706e67)

①、每个在线的 Sentinel 节点都有资格成为领导者，当它确认主节点下线时候，会向其他哨兵节点发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。

这个投票过程称为“Leader 选举”。**候选者会给自己先投 1 票，然后向其他 Sentinel 节点发送投票的请求**。

②、收到请求的 Sentinel 节点会进行判断，**如果候选者的日志与自己的日志一样新，任期号也小于自己，且之前没有投票过，就会同意投票，回复 Y。否则回复 N**。

③、候选者收到投票后会统计支持自己的得票数，如果候选者获得了集群中**超过半数节点**的投票支持（即多数原则），它将成为新的主节点。

新的主节点在确立后，会向其他从节点发送心跳信号，告诉它们自己已经成为主节点，并将其他节点的状态重置为从节点。

④、如果多个节点同时成为候选者，并且都有可能获得足够的票数，这种情况下可能会出现**选票分裂**。也就是没有候选者获得超过半数的选票，那么这次选举就会失败，所有候选者都会**再次发起选举**。

为了防止无限制的选举失败，每个节点都会有一个**选举超时时间**，且是随机的。





### 新的主节点是怎样被挑选出来的？

选出新的主节点，大概分为这么几步：

 [![新的主节点](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210759692.png)](https://camo.githubusercontent.com/5eac65391db6ed9ee54fbcc29ec9836fa753d9a95fed5a0372c91ef279208d36/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d30333937366433352d323062362d346566652d616139632d3764333735393436306433342e706e67)

1. **过滤：“不健康”（主观下线、断线）**、5 秒内没有回复过 Sentinel 节 点 ping 响应、与主节点失联超过 down-after-milliseconds*10 秒。
2. 选择 **slave-priority（从节点优先级）最高的从节点**列表，如果存在则返回，不存在则继续。
3. 选择**复制偏移量最大的从节点（复制的最完整）**，如果存在则返 回，不存在则继续。
4. 选择 **runid 最小**的从节点。





### Redis 集群了解吗？

[![Redis 集群示意图](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210800281.png)](https://camo.githubusercontent.com/83310e28e6429f79339bd738b3f0df6588f9cff20dfc242930c6cc19b6b9a1d5/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d35636263363030392d323531652d346435622d386632322d3864353433393338656363622e706e67)

1. **数据分区：** 数据分区 *(或称数据分片)* 是集群最核心的功能。集群将数据分散到多个节点，一方面 突破了 Redis 单机内存大小的限制，**存储容量大大增加**；**另一方面** 每个主节点都可以对外提供读服务和写服务，**大大提高了集群的响应能力**。
2. **高可用：** 集群支持主从复制和主节点的 **自动故障转移** *（与哨兵类似）*，当任一节点发生故障时，集群仍然可以对外提供服务。





### Redis Cluster了解吗？

切片集群是一种将数据分片存储在多个 Redis 实例上的集群架构，每个 Redis 实例负责存储部分数据。

![极客时间：切片集群架构图](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210801719.png)

官方提供了 Redis Cluster，数据和实例之间的映射通过**哈希槽**（hash slot）来实现。

Redis Cluster 有 **16384 个哈希槽**，**每个键根据其名字的 CRC16 值被映射到这些哈希槽上**。然后，这些哈希槽会被均匀地分配到所有的 Redis 实例上。

> CRC16 是一种哈希算法，它可以将任意长度的输入数据映射为一个 16 位的哈希值。

[![三分恶面渣逆袭：槽](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210802239.png)](https://camo.githubusercontent.com/b091b891d20b2c0feaad77a9c9ce99690cdc39113873835eb1e85b145d6b25a5/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d65306564396436322d333430362d343064622d386230312d6339333166313032303631322e706e67)

例如，如果我们有 3 个 Redis 实例，那么每个实例可能会负责大约 5461 个哈希槽。

当需要存储或检索一个键值对时，Redis Cluster 会先计算这个键的哈希槽，然后找到负责这个哈希槽的 Redis 实例，最后在这个实例上进行操作。





### 集群中数据如何分区？

![三分恶面渣逆袭：分布式数据分区](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210803322.png)

#### 说说节点取余分区

缺点是扩缩容时，大多数数据需要重新分配，因为节点总数的改变会影响取余结果，这可能导致大量数据迁移。

[![三分恶面渣逆袭：节点取余分区](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210803534.png)](https://camo.githubusercontent.com/4af6fe036bb11fc7cf7e08c09f1cc8c6f60f67121e25736ccff9c4d607eb7d4a/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d38623166636165632d333765362d343230612d396361322d3033363135323332616631372e706e67)

#### 说说一致性哈希分区

一致性哈希分区的原理是：将哈希值空间组织成一个环，数据项和节点都映射到这个环上。数据项由其哈希值直接映射到环上，然后顺时针分配到遇到的第一个节点。

从而来减少节点变动时数据迁移的量。

[![三分恶面渣逆袭：一致性哈希分区](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210804759.png)](https://camo.githubusercontent.com/982a7433f2ec8d50051218397455a588fc3a680a62e49e3ff01a3431bd60c669/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d38396264316331632d323531632d346635332d626261332d6665393435623261653965322e706e67)

Key 1 和 Key 2 会落入到 Node 1 中，Key 3、Key 4 会落入到 Node 2 中，Key 5 落入到 Node 3 中，Key 6 落入到 Node 4 中。

这种方式相比节点取余最大的好处在于加入和删除节点只影响哈希环中相邻的节点，对其他节点无影响。

但它还是存在问题：

- 节点在圆环上分布不平均，会造成部分缓存节点的压力较大
- 当某个节点故障时，这个节点所要承担的所有访问都会被顺移到另一个节点上，会对后面这个节点造成压力。

#### 说说哈希槽分区？

在虚拟槽（也叫哈希槽）分区中，槽位的数量是固定的（例如 Redis Cluster 有 16384 个槽），每个键通过哈希算法（比如 CRC16）映射到这些槽上，每个集群节点负责管理一定范围内的槽。

这种分区可以灵活地将槽（以及槽中的数据）从一个节点迁移到另一个节点，从而实现**平滑扩容和缩容**；数据分布也更加均匀，Redis Cluster 采用的正是这种分区方式。

[![三分恶面渣逆袭：虚拟槽分配](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210805163.png)](https://camo.githubusercontent.com/b091b891d20b2c0feaad77a9c9ce99690cdc39113873835eb1e85b145d6b25a5/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d65306564396436322d333430362d343064622d386230312d6339333166313032303631322e706e67)

假设系统中有 4 个实际节点，假设为其分配了 16 个槽(0-15)；

- 槽 0-3 位于节点 node1；
- 槽 4-7 位于节点 node2；
- 槽 8-11 位于节点 node3；
- 槽 12-15 位于节点 node4。

如果此时删除 `node2`，只需要将槽 4-7 重新分配即可，例如将槽 4-5 分配给 `node1`，槽 6 分配给 `node3`，槽 7 分配给 `node4`，数据在节点上的分布仍然较为均衡。

如果此时增加 node5，也只需要将一部分槽分配给 node5 即可，比如说将槽 3、槽 7、槽 11、槽 15 迁移给 node5，节点上的其他槽位保留。

当然了，这取决于 `CRC16(key) % 槽的个数` 的具体结果。因为**在 Redis Cluster 中，槽的个数刚好是 2 的 14 次方，这和 HashMap 中数组的长度必须是 2 的幂次方有着异曲同工之妙**。

它能**保证扩容后，大部分数据停留在扩容前的位置，只有少部分数据需要迁移到新的槽上**。





### 能说说 Redis 集群的原理吗？

Redis 集群通过**数据分区**来实现数据的分布式存储，通过**自动故障**转移实现高可用。



#### 故障转移

Redis 集群的故障转移和哨兵的故障转移类似，但是 Redis 集群中所有的节点都要承担状态维护的任务。

**故障恢复**

故障节点变为客观下线后，如果下线节点是持有槽的主节点则需要在它 的从节点中选出一个替换它，从而保证集群的高可用。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210809069.png" alt="image-20241221080918971" style="zoom:50%;" />

#### 部署 Redis 集群至少需要几个物理节点？

在投票选举的环节，故障主节点也算在投票数内，假设集群内节点规模是 3 主 3 从，其中有 2 个主节点部署在一台机器上，当这台机器宕机时，由于从节点无法收集到 3/2+1 个主节点选票将导致故障转移失败。这个问题也适用于故障发现环节。因此部署集群时**所有主节点最少需要部署在 3 台物理机上才能避免单点问题**。



### 说说集群的伸缩？

Redis 集群使用**数据分片和哈希槽**的机制将数据分布到不同的节点上。集群扩容和缩容的关键，在于**槽和节点之间的对应关系。**



当需要扩容时，新的节点被添加到集群中，集群会自动执行数据迁移，以重新分布哈希槽到新的节点。数据迁移的过程可以确保在扩容期间数据的正常访问和插入。

当数据正在迁移时，**客户端请求可能被路由到原有节点或新节点**。Redis Cluster 会根据哈希槽的映射关系判断请求应该被路由到哪个节点，并在必要时进行重定向。

如果请求被路由到正在迁移数据的哈希槽，Redis Cluster 会返回一个 **MOVED 响应**，指示客户端重新路由请求到正确的目标节点。这种机制也就保证了数据迁移过程中的**最终一致性**。



当需要缩容时，Redis 集群会**将槽从要缩容的节点上迁移到其他节点上**，然后将要缩容的节点从集群中移除。





## 缓存设计

### :star:缓存击穿、缓存穿透、缓存雪崩了解吗？

见redis高级篇，略



### 能说说布隆过滤器吗？

![image-20241221081905047](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210819137.png)

#### 布隆过滤器支持删除吗？

布隆过滤器其实并**不支持删除元素**，因为多个元素可能哈希到一个布隆过滤器的同一个位置，如果**直接删除该位置的元素，则会影响其他元素的判断。**

#### 为什么不能用哈希表而是用布隆过滤器？

布隆过滤器是一种基于位数组和多个哈希函数的概率型数据结构，适合在内存资源有限、数据量大且能容忍一定误判的场景下使用。

相比哈希表，布隆过滤器的内存开销非常小，能快速判断一个元素是否存在。虽然它存在误判，但不会漏报，因此在防止缓存穿透、黑名单过滤和推荐系统去重等场景中广泛使用。



**哈希表**虽然可以精准判断元素存在与否，但需要存储实际数据，**内存开销大，不适合大规模数据存储**。



#### 布隆过滤器的优点？

1. **内存效率高**：布隆过滤器**只需要存储每个元素的哈希值**，而不需要存储元素本身，因此**内存占用非常小。**
2. **查询速度快**：布隆过滤器只需要将元素通过多个哈希函数映射到位数组，并检查位状态即可。它不需要哈希表那样的复杂键值操作，**时间复杂度接近常数时间**，速度非常快。





### 如何保证缓存和数据库的数据⼀致性？

#### 那再说说为什么要先更新数据库，再删除缓存

因为更新数据库的速度比删除缓存的速度要慢得多。

那假如是先删除缓存，再更新数据库，就会造成这样的情况：

缓存中不存在，数据库又没有完成更新，此时有请求进来读取数据，并写入到缓存，那么在更新完缓存后，缓存中这个 key 就成了一个脏数据。

目前最流行的缓存读写策略 **Cache Aside Pattern（[旁路缓存模式](https://coolshell.cn/articles/17416.html)）**就是采用的先写数据库，再删缓存的方式。



### 如何保证本地缓存和分布式缓存的一致？

为了减轻 Redis 的负载，我又追加了一层本地缓存 Caffeine，为了保证本地缓存和 Redis 缓存的一致性，通常采用的策略有：

①、**设置本地缓存的过期时间**，这是最简单也是最直接的方法，当本地缓存过期时，就从 Redis 缓存中去同步。

②、使用 Redis 的 **Pub/Sub 机制**，当 Redis 缓存发生变化时，发布一个消息，本地缓存订阅这个消息，然后删除对应的本地缓存。

③、Redis 缓存发生变化时，引入**消息队列**，比如 RocketMQ、RabbitMQ 去更新本地缓存。

[![三分恶面渣逆袭：本地缓存/分布式缓存保持一致](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210827182.png)](https://camo.githubusercontent.com/a2c043342e2eb57a835e014cbb8894ad94cf878e3b12fdf45621410b255ef3b5/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d32306331356630642d666233632d343932322d393462312d6564636438353636353862652e706e67)

#### 如果在项目中多个地方都要使用到二级缓存的逻辑，如何设计这一块？

在设计时，应该清楚地区分何时使用一级缓存和何时使用二级缓存。通常情况下，对于**频繁访问但不经常更改的数据，可以放在本地缓存**中以提供最快的访问速度。而对于**需要共享或者一致性要求较高的数据，应当放在一级缓存中**。



#### 本地缓存和 Redis 缓存的区别和效率对比？

Redis 可以部署在多个节点上，支持数据分片，适用于跨服务器的缓存共享。而本地缓存只能在单个服务器上使用。

Redis 还可以**持久化**数据，支持数据备份和恢复，适用于对数据安全性要求较高的场景。并且支持发布/订阅、事务、Lua 脚本等高级功能。

效率上，Redis 和本地缓存都是存储在内存中，读写速度都非常快。





### 怎么处理热 key？

所谓的热 key，就是指在很短时间内被频繁访问的键。

![三分恶面渣逆袭：热key处理](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210835673.png)

对热 key 的处理，最关键的是对热 key 的监控:

①、客户端

客户端其实是距离 key“最近”的地方，因为 Redis 命令就是从客户端发出的，例如在客户端设置全局字典（key 和调用次数），每次调用 Redis 命令时，使用这个字典进行记录。

②、代理端

像 Twemproxy、Codis 这些基于代理的 Redis 分布式架构，所有客户端的请求都是通过代理端完成的，可以在代理端进行监控。

③、Redis 服务端

使用 **monitor 命令**统计热点 key 是很多开发和运维人员首先想到的方案，monitor 命令可以监控到 Redis 执行的所有命令。

还可以通过 **bigkeys 参数**来分析热 Key。



①、**把热 key 打散到不同的服务器**，降低压力。

基本思路就是给热 Key **加上前缀或者后缀**

②、**加⼊⼆级缓存**，当出现热 Key 后，把热 Key 加载到 JVM 中，后续针对这些热 Key 的请求，直接从 JVM 中读取。

这些本地的缓存工具有很多，比如 Caffeine、Guava 等，或者直接使用 HashMap 作为本地缓存都是可以的。

注意，如果对热 Key 进行本地缓存，需要防止本地缓存过大。





### 缓存预热怎么做呢？

缓存预热是指在系统启动时，提前将一些预定义的数据加载到缓存中，以避免在系统运行初期由于缓存未命中（cache miss）导致的性能问题。

通过缓存预热，可以确保系统在上线后能够立即提供高效的服务，减少首次访问时的延迟。

项目启动时**自动加载**和**定时预热**两种方式





### 热点 key 重建？问题？解决？

- 当前 key 是一个热点 key（例如一个热门的娱乐新闻），并发量非常大。
- 重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的 SQL、多次 IO、多个依赖等。 在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃。



要解决这个问题也不是很复杂，解决问题的要点在于：

- **减少重建缓存的次数。**
- **数据尽可能一致。**
- 较少的潜在危险。

所以一般采用如下方式：

1. **互斥锁**（mutex key） 这种方法**只允许一个线程重建缓存**，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。
2. **永远不过期** “永远不过期”包含两层意思：

- 从缓存层面来看，确实**没有设置过期时间**，所以不会出现热点 key 过期后产生的问题，也就是“物理”不过期。
- 从功能层面来看，为每个 value 设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去构建缓存**续约**。





### 无底洞问题吗？如何解决？

为了满足业务要求添加了大量新节点，但是发现性能不但没有好转反而下降了

批量操作通常需要从不同节点上获取，相比于单机批量操作只涉及一次网络操作，分布式批量操作会涉及**多次网络时间。**

#### 解决

- 命令本身的优化，例如优化操作语句等。
- 减少网络通信次数。
- 降低接入成本，例如客户端使用长连/连接池、NIO 等。







## Redis 运维

### Redis 报内存不足怎么处理？

Redis 内存不足有这么几种处理方式：

- 修改配置文件 redis.conf 的 maxmemory 参数，增加 Redis 可用内存
- 也可以通过命令 set maxmemory 动态设置内存上限
- 修改内存淘汰策略，及时释放内存空间
- 使用 Redis 集群模式，进行横向扩容。



### Redis key 过期策略有哪些？

Redis 的 key 过期回收策略主要有两种：惰性删除和定期删除。

[![二哥的 Java 进阶之路：Redis 的过期淘汰策略](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210856941.png)](https://camo.githubusercontent.com/c95c718527898ff38d0774dfe085ad2a3875ac1ee1972bec7ff97ae450d42e53/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f73747574796d6f72652f72656469732d32303234303332363231343131392e706e67)



### Redis 有哪些内存淘汰策略？

当 Redis 的内存使用达到最大值时，它会根据配置的内存淘汰策略来决定如何处理新的请求。

> 最大值通过 maxmemory 参数设置

[![三分恶面渣逆袭：Redis六种内存溢出控制策略](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210857106.png)](https://camo.githubusercontent.com/596235604048ef7202d6cd3a50424f37176c0fae55b46c7314b386610de9454e/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d35626537343035632d656531312d346432622d626561342d3935393866313061316231372e706e67)

常见的策略有：

1. noeviction：默认策略，不进行任何数据淘汰，直接返回错误信息。
2. allkeys-lru：从所有键中，使用 LRU 算法淘汰最近最少使用的键。
3. allkeys-lfu：从所有键中，使用 LFU 算法淘汰最少使用的键。
4. volatile-lru：从设置了过期时间的键中淘汰最近最少使用的键。
5. volatile-ttl：从设置了过期时间的键中淘汰即将过期的键。



#### LRU 和 LFU 的区别是什么？

**LRU**（Least Recently Used）：基于时间维度，淘汰**最近最少访问**的键。适合访问具有时间特性的场景。

**LFU**（Least Frequently Used）：基于次数维度，淘汰**访问频率最低**的键。更适合长期热点数据场景。





### Redis 阻塞？怎么解决？

Redis 发生阻塞，可以从以下几个方面排查： [![Redis阻塞排查](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210900930.png)](https://camo.githubusercontent.com/b61a2d93e1225ce4ce81d7958d725d51ef37a6d04074d03ab76cdde2c5660d7a/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d65366133353235382d376137382d343438392d393062372d6534376134313930383032622e706e67)

- **持久化相关的阻塞**

  对于开启了持久化功能的 Redis 节点，需要排查是否是持久化导致的阻塞。

  1. fork 阻塞 fork 操作发生在 RDB 和 AOF 重写时，Redis 主线程调用 fork 操作产生共享 内存的子进程，由子进程完成持久化文件重写工作。如果 fork 操作本身耗时过长，必然会导致主线程的阻塞。
  2. AOF 刷盘阻塞 当我们开启 AOF 持久化功能时，文件刷盘的方式一般采用每秒一次，后台线程每秒对 AOF 文件做 fsync 操作。当硬盘压力过大时，fsync 操作需要等 待，直到写入完成。如果主线程发现距离上一次的 fsync 成功超过 2 秒，为了 数据安全性它会阻塞直到后台线程执行 fsync 操作完成。
  3. HugePage 写操作阻塞 对于开启 Transparent HugePages 的 操作系统，每次写命令引起的复制内存页单位由 4K 变为 2MB，放大了 512 倍，会拖慢写操作的执行时间，导致大量写操作慢查询。





### 大 key 问题了解吗？

大 key 指的是存储了大量数据的键，比如：

- 单个简单的 key 存储的 value 很大，size 超过 10KB
- hash，set，zset，list 中存储过多的元素（以万为单位）

#### 如何找到大 key?

①、**bigkeys 参数**：使用 bigkeys 命令以遍历的方式分析 Redis 实例中的所有 Key，并返回整体统计信息与每个数据类型中 Top1 的大 Key

> bigkeys 命令的使用：`redis-cli --bigkeys`

②、**redis-rdb-tools**：redis-rdb-tools 是由 Python 语言编写的用来分析 Redis 中 rdb 快照文件的工具。



#### 如何处理大 key?

[![大key处理](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210906454.png)](https://camo.githubusercontent.com/8a7e824c5cef5e735fcf91d5687e18b9bf5a552d939a8efa6e8acb7f67775e95/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d65346161616664612d666365312d343766302d386232622d3732363164343762373230622e706e67)

①、**删除大 key**

- 当 Redis 版本大于 4.0 时，可使用 **UNLINK 命令**安全地删除大 Key，该命令能够以**非阻塞**的方式，逐步地清理传入的大 Key。
- 当 Redis 版本小于 4.0 时，建议通过 **SCAN 命令**执行**增量迭代扫描 key**，然后判断进行删除。

②、**压缩和拆分 key**

- 当 vaule 是 string 时，比较难拆分，则使用**序列化、压缩算法**将 key 的大小控制在合理范围内，但是序列化和反序列化都会带来额外的性能消耗。
- 当 value 是 string，压缩之后仍然是大 key 时，则需要进行拆分，将一个大 key 分为不同的部分，记录每个部分的 key，使用 **multiget 等操作实现事务读取**。
- 当 value 是 list/set 等集合类型时，根据预估的数据规模来进行**分片**，不同的元素计算后分到不同的片。





### Redis 常见性能问题和解决方案？

1. **Master 最好不要做任何持久化工作**，包括内存快照和 AOF 日志文件，特别是不要启用内存快照做持久化。
2. 如果数据比较关键，某个 **Slave 开启 AOF** 备份数据，策略为每秒同步一次。
3. 为了主从复制的速度和连接的稳定性，Slave 和 Master 最好在**同一个局域网**内。
4. **尽量避免在压力较大的主库上增加从库**。
5. Master 调用 BGREWRITEAOF 重写 AOF 文件，AOF 在重写的时候会占大量的 CPU 和内存资源，导致服务 load 过高，出现短暂服务暂停现象。
6. 为了 Master 的稳定性，**主从复制不要用图状结构**，**用单向链表**结构更稳定，即主从关为：Master<–Slave1<–Slave2<–Slave3…，这样的结构也方便解决单点故障问题，实现 Slave 对 Master 的替换，也即，如果 Master 挂了，可以立马启用 Slave1 做 Master，其他不变。





## Redis 应用

- **使用 list 作为队列，lpush 生产消息，rpop 消费消息**

这种方式，消费者死循环 rpop 从队列中消费消息。但是这样，即使队列里没有消息，也会进行 rpop，会导致 Redis CPU 的消耗。 [![list作为队列](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210912758.png)](https://camo.githubusercontent.com/3549af0b3e977523e59b71c41f553e28d8b306828873d63725f251507a520bf9/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d65346231393261312d336261372d346634652d393864652d6539336634333763666637632e706e67) 可以通过让消费者休眠的方式的方式来处理，但是这样又会又消息的延迟问题。

- **使用 list 作为队列，lpush 生产消息，brpop 消费消息**

brpop 是 rpop 的阻塞版本，list 为空的时候，它会一直阻塞，直到 list 中有值或者超时。 [![list作为队列，brpop](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210913398.png)](https://camo.githubusercontent.com/2cbef93dd9ab85b85a60155cdb4e07fc299d766a3d2fe649386cf28b6a430f02/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d65393538316535312d666663382d343332362d396166342d3037383136373433646338382e706e67)

这种方式**只能实现一对一的消息队列**。

- **使用 Redis 的 pub/sub 来进行消息的发布/订阅**

发布/订阅模式可以 1：N 的消息发布/订阅。发布者将消息发布到指定的频道频道（channel），订阅相应频道的客户端都能收到消息。

![image-20241221091450948](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210914057.png) 但是这种方式不是可靠的，它**不保证订阅者一定能收到消息，也不进行消息的存储**。

所以，一般的异步队列的实现还是交给专业的消息队列。





### Redis 如何实现延时队列?

可以使用 Redis 的 **zset**（有序集合）来实现延时队列。

[![三分恶面渣逆袭：zset实现延时队列](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210915338.png)](https://camo.githubusercontent.com/438a4e7e93a8490edfb09271bd25fe9d4bca64709b219b989ee5aa5fb1f334ed/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d35346262636333362d306230302d343134322d613665622d6266326566343863323231332e706e67)

第一步，将任务添加到 zset 中，score 为任务的执行时间戳，value 为任务的内容。

```sh
ZADD delay_queue 1617024000 task1
```

第二步，定期（例如每秒）从 zset 中获取 score 小于当前时间戳的任务，然后执行任务。

```sh
ZREMRANGEBYSCORE delay_queue -inf 1617024000
```

第三步，任务执行后，从 zset 中删除任务。

```sh
ZREM delay_queue task1
```





### Redis 支持事务吗？

Redis 支持简单的事务，可以将多个命令打包，然后一次性的，按照顺序执行。主要通过 multi、exec、discard、watch 等命令来实现：

- multi：标记一个事务块的开始
- exec：执行所有事务块内的命令
- discard：取消事务，放弃执行事务块内的所有命令
- watch：监视一个或多个 key，如果在事务执行之前这个 key 被其他命令所改动，那么事务将被打断



#### 说一下 Redis 事务的原理？

**使用队列实现**

[![三分恶面渣逆袭：Redis事务](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210918818.png)](https://camo.githubusercontent.com/4ccf339b684afdb1ee71cdfc0cdf442a89ca0598c3383547fa96be539863ee40/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f746f62656265747465726a61766165722f696d616765732f736964656261722f73616e66656e652f72656469732d32656437616532312d313661362d343731362d616338392d3131376138633736643364622e706e67)

- WATCH 命令用于实现**乐观锁**。WATCH 命令可以监视一个或多个键，如果在执行事务的过程中（即在执行 MULTI 之后，执行 EXEC 之前），被监视的键被其他命令改变了，那么当执行 EXEC 时，事务将被取消，并且返回一个错误。



#### Redis 事务的注意点有哪些？

Redis 事务是不支持回滚的，一旦 EXEC 命令被调用，所有命令都会被执行，即使有些命令可能执行失败。



#### Redis 事务为什么不支持回滚？

引入事务回滚机制会大大增加 Redis 的复杂性，因为需要跟踪事务中每个命令的状态，并在发生错误时逆向执行命令以恢复原始状态。

Redis 是一个基于内存的数据存储系统，其**设计重点是实现高性能**。事务回滚需要额外的资源和时间来管理和执行，这与 Redis 的设计目标相违背。因此，Redis 选择不支持事务回滚。

换句话说，**就是我 Redis 不想支持事务，也没有这个必要**。



#### Redis 事务的 ACID 特性如何体现？

ACID 一般指 MySQL 事务中的四个特性：原子性、一致性、隔离性、持久性。虽然 Redis 提供了事务的支持，但它在 ACID 上的表现与 MySQL 有所不同。

Redis 事务中，所有命令会依次执行，但并不支持部分失败后的自动回滚。因此 **Redis 在事务层面并不能保证一致性**，我们必须通过程序逻辑来进行优化。

Redis 事务在**一定程度上提供了隔离性，事务中的命令会按顺序执行**，不会被其他客户端的命令插入。

Redis 的**持久性依赖于其持久化机制（如 RDB 和 AOF），而不是事务本身**。



#### Redis事务满足原子性吗？要怎么改进？

不满足，Redis 事务不支持回滚，一旦 EXEC 命令被调用，所有命令都会被执行，即使有些命令可能执行失败。

可以通过 **Lua 脚本来实现事务的原子性**，Lua 脚本在 Redis 中是原子执行的，执行过程中间不会插入其他命令。





### 有 Lua 脚本操作 Redis 的经验吗？

比如秒杀系统是一个经典场景，我们可以用 Lua 脚本来实现扣减 Redis 库存的功能。

```lua
-- 库存未预热
if (redis.call('exists', KEYS[2]) == 1) then
    return -9;
end;
-- 秒杀商品库存存在
if (redis.call('exists', KEYS[1]) == 1) then
    local stock = tonumber(redis.call('get', KEYS[1]));
    local num = tonumber(ARGV[1]);
    -- 剩余库存少于请求数量
    if (stock < num) then
        return -3
    end;
    -- 扣减库存
    if (stock >= num) then
        redis.call('incrby', KEYS[1], 0 - num);
        -- 扣减成功
        return 1
    end;
    return -2;
end;
-- 秒杀商品库存不存在
return -1;
```





### Redis 的管道Pipeline了解吗？

Pipeline 是 Redis 提供的一种优化手段，允许客户端一次性向服务器**发送多个命令，而不必等待每个命令的响应**，从而减少网络延迟。它的**工作原理类似于批量操作**，即多个命令一次性打包发送，Redis 服务器依次执行后再将结果一次性返回给客户端。

#### 底层实现

在 Pipeline 模式下，客户端不会在每条命令发送后立即等待 Redis 的响应，而是将**多个命令依次写入 TCP 缓冲区**，所有命令一起发送到 Redis 服务器。

Redis 服务器接收到批量命令后，**依次**执行每个命令。

Redis 服务器执行完所有命令后，将每条命令的结果一次性打包**通过 TCP** 返回给客户端。

客户端一次性接收所有返回结果，并解析每个命令的执行结果。





### Redis 实现分布式锁了解吗？







## 补充

### 假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如何将它们全部找出来？

使用 **`keys` 指令**可以扫出指定模式的 key 列表。但是要注意 keys 指令会导致线程**阻塞**一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 **`scan` 指令**，`scan` 指令可以**无阻塞**的提取出指定模式的 `key` 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 `keys` 指令长。





### Redis 的秒杀场景下扮演了什么角色？

前端页面的静态化、按钮防抖也能够有效的减轻服务器的压力。

- 页面静态化：将商品详情等页面静态化，使用 CDN 分发。
- 按钮防抖：避免用户因频繁点击造成的额外请求，比如设定间隔时间后才能再次点击。

#### 如何实现错峰削峰呢？

①、**预热缓存**：提前将热点数据加载到 Redis 缓存中，减少对数据库的访问压力。

②、**消息队列**：引入消息队列，将请求异步处理，减少瞬时请求压力。消息队列就像一个水库，可以削减上游的洪峰流量。

③、**多阶段多时间窗口**：将秒杀活动分为多个阶段，每个阶段设置不同的时间窗口，让用户在不同的时间段内参与秒杀活动。

④、**插入答题系统**：在秒杀活动中加入答题环节，只有答对题目的用户才能参与秒杀活动，这样可以减少无效请求。



#### 如何限流呢？

采用**令牌桶算法**，它就像在帝都买车，摇到号才有资格，没摇到就只能等下一次（😁）。

在实际开发中，我们需要维护一个容器，按照固定的速率往容器中放令牌（token），当请求到来时，从容器中取出一个令牌，如果容器中没有令牌，则拒绝请求。

[![李子捌：令牌桶](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412210942960.png)](https://camo.githubusercontent.com/dec7a1a47eb437f8fad4cf5d2f3ca7aa73dda64e703767fefefb637a9c7798b9/68747470733a2f2f63646e2e746f62656265747465726a61766165722e636f6d2f73747574796d6f72652f72656469732d32303234303432303131343032352e706e67)

第一步，使用 Redis 初始化令牌桶：

第二步，使用 Lua 脚本实现令牌桶算法；假设每秒向桶中添加 10 个令牌，但不超过桶的最大容量。

第三步，使用 Shell 脚本调用 Lua 脚本：

第四步，当请求到达时，需要检查并消耗一个令牌。

调用 Lua 脚本

































































































































































































































































































































































































































































































































