# 计算机网络

# 一、网络模型

## TCP/IP模型

网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318702.png" alt="image-20241202183746436" style="zoom:50%;" />

![image-20241202184136379](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412021846121.png)





## 键入网址到网页显示的过程

### 1、HTTP

**HTTP报文格式**：

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318444.png" alt="image-20241202184247736" style="zoom:50%;" />



<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318044.png" alt="image-20241202184448842" style="zoom:50%;" />

> 要是上图中的蓝色部分 URL 元素都省略了，那应该是请求哪个文件呢？

当没有路径名时，就代表访问根目录下事先设置的**默认文件**，也就是 `/index.html` 或者 `/default.html` 这些文件，这样就不会发生混乱了。



### 2、DNS

域名解析的工作流程

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318513.png" alt="image-20241202184341194" style="zoom: 40%;" />

DNS 域名解析的过程蛮有意思的，整个过程就和我们日常生活中找人问路的过程类似，**只指路不带路**。

> 那是不是每次解析域名都要经过那么多的步骤呢？

当然不是了，还有缓存这个东西的嘛。

浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地 DNS 服务器」。



### 3、协议栈

通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的**协议栈**。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318483.png" alt="image-20241202184931841" style="zoom: 33%;" />

协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。

此外 IP 中还包括 `ICMP` 协议和 `ARP` 协议。

- `ICMP` 用于告知网络包传送过程中产生的错误以及各种控制信息。
- `ARP` 用于根据 IP 地址查询相应的以太网 MAC 地址。



### 4、TCP

**TCP报文格式**：

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412021850770.png" alt="image-20241202185026650" style="zoom:33%;" />

首先，**源端口号**和**目标端口**号是不可少的，如果没有这两个端口号，数据就不知道应该发给哪个应用。

接下来有包的**序**号，这个是为了解决包乱序的问题。

还有应该有的是**确认号**，目的是确认发出去对方是否有收到。如果没有收到就应该重新发送，直到送达，这个是为了解决不丢包的问题。

接下来还有一些**状态位**。例如 `SYN` 是发起一个连接，`ACK` 是回复，`RST` 是重新连接，`FIN` 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。

还有一个重要的就是**窗口大小**。TCP 要做**流量控制**，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。

除了做流量控制以外，TCP 还会做**拥塞控制**，对于真正的通路堵车不堵车，它无能为力，唯一能做的就是控制自己，也即控制发送的速度。不能改变世界，就改变自己嘛。



**三次握手：**

三次握手目的是**保证双方都有发送和接收的能力**。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318079.png" alt="image-20241202185225208" style="zoom: 33%;" />



> TCP 分割数据

如果 HTTP 请求消息比较长，超过了 `MSS` 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318702.webp" alt="MTU 与 MSS" style="zoom: 67%;" />](https://camo.githubusercontent.com/21cb60ee64ad88d670881128cf8f638d9076c6bc6dc4cb57d693df28dbdb586e/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f2545392539342541452545352538352541352545372542442539312545352539442538302545382542462538372545372541382538422f31312e6a7067)

- `MTU`：一个网络包的最大长度，以太网中一般为 `1500` 字节。
- `MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。

数据会被以 `MSS` 的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。



### 5、IP

**IP包头格式**

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318170.png" alt="image-20241202185739102" style="zoom: 67%;" />

在 IP 协议里面需要有**源地址 IP** 和 **目标地址 IP**：

- 源地址 IP，即是客户端输出的 IP 地址；
- 目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。

因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的**协议号**，要填写为 `06`（十六进制），表示协议为 TCP。



> 假设客户端有多个网卡，就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？

当存在多个网卡时，在填写源地址 IP 时，就需要判断到底应该填写哪个地址。这个判断相当于在多块网卡中判断应该使用哪个一块网卡来发送包。

这个时候就需要根据**路由表**规则，来判断哪一个网卡作为源地址 IP。

在 Linux 操作系统，我们可以使用 `route -n` 命令查看当前系统的路由表。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318743.png" alt="路由表" style="zoom:50%;" />](https://camo.githubusercontent.com/a1c32c650a434e3828ae2b5ea0eb9cc15d98c5ddba8795067677b6382b5c5e8d/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f2545392539342541452545352538352541352545372542442539312545352539442538302545382542462538372545372541382538422f31352e6a7067)

举个例子，根据上面的路由表，我们假设 Web 服务器的目标地址是 `192.168.10.200`。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318412.webp" alt="路由规则判断" style="zoom: 50%;" />](https://camo.githubusercontent.com/279014c70704fce4df49fe06c198958f5234cdb304d5abf7b530f1a76fdb49df/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f2545392539342541452545352538352541352545372542442539312545352539442538302545382542462538372545372541382538422f31362e6a7067)

1. 首先先和第一条目的子网掩码（`Genmask`）进行 **与运算**，得到结果为 `192.168.10.0`，但是第一个条目的 `Destination` 是 `192.168.3.0`，两者不一致所以匹配失败。
2. 再与第二条目的子网掩码进行 **与运算**，得到的结果为 `192.168.10.0`，与第二条目的 `Destination 192.168.10.0` 匹配成功，所以将使用 `eth1` 网卡的 IP 地址作为 IP 包头的源地址。

那么假设 Web 服务器的目标地址是 `10.100.20.100`，那么依然依照上面的路由表规则判断，判断后的结果是和第三条目匹配。

第三条目比较特殊，它目标地址和子网掩码都是 `0.0.0.0`，这表示**默认网关**，如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器，`Gateway` 即是路由器的 IP 地址。



### 6、MAC

**MAC包头格式**

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318660.png" alt="image-20241202190306491" style="zoom: 50%;" />

在 MAC 包头里需要**发送方 MAC 地址**和**接收方目标 MAC 地址**，用于**两点之间的传输**。

一般在 TCP/IP 通信里，MAC 包头的**协议类型**只使用：

- `0800` ：IP 协议
- `0806` ：ARP 协议



> MAC 发送方和接收方如何确认？

**发送方**的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。

**接收方**的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的 MAC 地址。

所以先得搞清楚应该把包发给谁，这个只要查一下**路由表**就知道了。在路由表中找到相匹配的条目，然后把包发给 `Gateway` 列中的 IP 地址就可以了。

> 既然知道要发给谁，那如何获取对方的 MAC 地址呢？

不知道对方 MAC 地址？不知道就喊呗。

此时就需要 `ARP` 协议帮我们找到路由器的 MAC 地址。

[![ARP 广播](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412021904763.png)](https://camo.githubusercontent.com/c358208e777869ccd680b795d7fb71dc2ca4db872781548bab8131e5c798b940/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f2545392539342541452545352538352541352545372542442539312545352539442538302545382542462538372545372541382538422f31392e6a7067)

ARP 协议会在以太网中以**广播**的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。

然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。

如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。

> 好像每次都要广播获取，这不是很麻烦吗？

放心，在后续操作系统会把本次查询结果放到一块叫做 **ARP 缓存**的内存空间留着以后用，不过缓存的时间就几分钟。

也就是说，在发包时：

- 先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。
- 而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。



### 7、网卡

将**数字信息转换为电信号**，负责执行这一操作的是**网卡**，要控制网卡还需要靠**网卡驱动程序**。

网卡驱动获取网络包之后，会将其**复制**到网卡内的缓存区中，接着会在其**开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列**。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318961.png" alt="image-20241202190708869" style="zoom: 50%;" />

- 起始帧分界符是一个用来表示包起始位置的标记
- 末尾的 `FCS`（帧校验序列）用来检查包传输过程是否有损坏

最后网卡会将包转为电信号，通过网线发送出去。



### 8、交换机

交换机的设计是将网络包**原样**转发到目的地。交换机工作在 MAC 层，也称为**二层网络设备**。



> 交换机的包接收操作

首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。

然后通过包末尾的 `FCS` 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。

**计算机的网卡本身具有 MAC 地址**，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，**交换机的端口不具有 MAC 地址**。

将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。

交换机的 MAC 地址表主要包含两个信息：

- 一个是设备的 MAC 地址，
- 另一个是该设备连接在交换机的哪个端口上。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412021909475.jpeg" alt="交换机的 MAC 地址表" style="zoom:50%;" />](https://camo.githubusercontent.com/094493c42bec88faaab1996ad37d80a658ea2823ff4c84b0a299c98202de4c45/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f2545392539342541452545352538352541352545372542442539312545352539442538302545382542462538372545372541382538422f32332e6a7067)

举个例子，如果收到的包的接收方 MAC 地址为 `00-02-B3-1C-9C-F9`，则与图中表中的第 3 行匹配，根据端口列的信息，可知这个地址位于 `3` 号端口上，然后就可以通过交换电路将包发送到相应的端口了。

所以，**交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口**。



> 当 MAC 地址表找不到指定的 MAC 地址会怎么样？

地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。

这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。

这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后**只有相应的接收者才接收包，而其他设备则会忽略这个包**。

有人会说：“这样做会发送多余的包，会不会造成网络拥塞呢？”

其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了。

局域网中每秒可以传输上千个包，多出一两个包并无大碍。

此外，如果接收方 MAC 地址是一个**广播地址**，那么交换机会将包发送到除源端口之外的所有端口。

以下两个属于广播地址：

- MAC 地址中的 `FF:FF:FF:FF:FF:FF`
- IP 地址中的 `255.255.255.255`



### 9、路由器

> 路由器与交换机的区别

网络包经过交换机之后，现在到达了**路由器**，并在此被转发到下一个路由器或目标设备。

这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。

不过在具体的操作过程上，路由器和交换机是有区别的。

- 因为**路由器**是基于 IP 设计的，俗称**三层**网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；
- 而**交换机**是基于以太网设计的，俗称**二层**网络设备，交换机的端口不具有 MAC 地址。



> 路由器基本原理

路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。

当转发包时，首先路由器端口会接收发给自己的以太网包，然后**路由表**查询转发目标，再由相应的端口作为发送方将以太网包发送出去。



> 路由器的包接收操作

首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 `FCS` 进行错误校验。

如果没问题则检查 MAC 头部中的**接收方 MAC 地址**，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。

总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。



> 查询路由表确定输出端口

完成包接收操作之后，路由器就会**去掉**包开头的 MAC 头部。

**MAC 头部的作用就是将包送达路由器**，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会**被丢弃**。

接下来，路由器会根据 MAC 头部后方的 `IP` 头部中的内容进行包的转发操作。

转发操作分为几个阶段，首先是查询**路由表**判断转发目标。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318837.webp" alt="路由器转发" style="zoom:50%;" />](https://camo.githubusercontent.com/20892b191a8250a876d433180fdbcb5532df785a345bf4f02cbf0bf39e5fb74c/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f2545392539342541452545352538352541352545372542442539312545352539442538302545382542462538372545372541382538422f32342e6a7067)

具体的工作流程根据上图，举个例子。

假设地址为 `10.10.1.101` 的计算机要向地址为 `192.168.1.100` 的服务器发送一个包，这个包先到达图中的路由器。

判断转发目标的第一步，就是根据包的接收方 IP 地址查询路由表中的目标地址栏，以找到相匹配的记录。

路由匹配和前面讲的一样，每个条目的子网掩码和 `192.168.1.100` IP 做 **& 与运算**后，得到的结果与对应条目的目标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续与下个条目进行路由匹配。

如第二条目的子网掩码 `255.255.255.0` 与 `192.168.1.100` IP 做 **& 与运算**后，得到结果是 `192.168.1.0` ，这与第二条目的目标地址 `192.168.1.0` 匹配，该第二条目记录就会被作为转发目标。

实在找不到匹配路由时，就会选择**默认路由**，路由表中子网掩码为 `0.0.0.0` 的记录表示「默认路由」。



> 路由器的发送操作

接下来就会进入包的**发送操作**。

首先，我们需要根据**路由表的网关列**判断对方的地址。

- 如果网关是一个 IP 地址，则这个 IP 地址就是我们要转发到的目标地址，**还未抵达终点**，还需继续需要路由器转发。
- 如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明**已抵达终点**。

知道对方的 IP 地址之后，接下来需要通过 `ARP` 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。

路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。

接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 `0800` （十六进制）表示 IP 协议。

网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。

发送出去的网络包会通过**交换机**到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。

接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。

不知你发现了没有，在网络包传输的过程中，**源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址（NAT除外）**，因为需要 MAC 地址在以太网内进行**两个设备**之间的包传输。



### 10、客户端与服务端

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318637.png" alt="image-20241202213746700" style="zoom:50%;" />

最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。





# 二、HTTP

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318284.png" alt="image-20241202214036012" style="zoom: 50%;" />

## HTTP基础



### HTTP基本概念

HTTP 是超文本传输协议，也就是**H**yper**T**ext **T**ransfer **P**rotocol。



#### HTTP 常见的状态码有哪些？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412022142298.png" alt="image-20241202214203194" style="zoom: 50%;" />

`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

- 「**101 Switching Protocols**」协议切换，服务器已经理解了客户端的请求，并将通过 Upgrade 消息头通知客户端采用不同的协议来完成这个请求。比如切换到一个实时且同步的协议（如 WebSocket）以传送利用此类特性的资源。

`2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

- 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
- 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
- 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

`3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

- 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
- 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

- 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

- 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
- 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
- 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

`5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

- 「**500 Internal Server Error**」与 400 类似，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
- 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
- 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
- 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。



#### HTTP 常见字段有哪些？

***Host* 字段：**客户端发送请求时，用来指定服务器的域名。

```plain
Host: www.A.com
```



***Content-Length 字段*：**服务器在返回数据时，会有 `Content-Length` 字段，表明本次回应的数据长度。

```plain
Content-Length: 1000
```

**HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题**。



***Connection 字段*：**`Connection` 字段最常用于客户端要求服务器使用「HTTP 长连接」机制，以便其他请求复用。

HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。

HTTP/1.1 版本的默认连接都是长连接，但为了兼容老版本的 HTTP，需要指定 `Connection` 首部字段的值为 `Keep-Alive`。

```plain
Connection: Keep-Alive
```

不要把 HTTP Keep-Alive 和 TCP Keepalive 搞混了，这两个虽然长的像，但是不是一个东西



***Content-Type 字段*：**`Content-Type` 字段用于服务器回应时，告诉客户端，本次数据是什么格式。

```plain
Content-Type: text/html; Charset=utf-8
```



**Accept 字段：**声明自己可以接受哪些数据格式。

```plain
客户端声明自己可以接受任何格式的数据。
Accept: */*
```



***Content-Encoding 字段***：`Content-Encoding` 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式

```plain
Accept-Encoding: gzip, deflate
```



### GET 与 POST

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412022154465.png" alt="image-20241202215419356" style="zoom:50%;" />

根据 RFC 规范，**GET 的语义是从服务器获取指定的资源**。GET 请求的参数位置一般是写在 URL 中，GET 请求的参数只允许 ASCII 字符，而且浏览器会对 URL 的长度有限制（HTTP 协议本身对 URL 长度并没有做任何规定）。

根据 RFC 规范，**POST 的语义是根据请求负荷（报文 body）对指定的资源做出处理**，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。



#### GET 和 POST 方法都是安全和幂等的吗？

所谓的「安全」是指请求方法不会「破坏」服务器上的资源。

- **GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，**可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如 nginx），而且在浏览器中 GET 请求可以保存为书签**。
- **POST** 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。所以，**浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签**。



GET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。

POST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。



如果「安全」放入概念是指信息是否会被泄漏的话，虽然 POST 用 body 传输数据，而 GET 用 URL 传输，这样数据会在浏览器地址栏容易看到，但是并不能说 GET 不如 POST 安全的。



> GET 请求可以带 body 吗？

RFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。

另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。



### HTTP 缓存技术

HTTP 缓存有两种实现方式，分别是**强制缓存和协商缓存**。

#### 强制缓存

强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。

如下图中，返回的是 200 状态码，但在 size 项中标识的是 from disk cache，就是使用了强制缓存。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318529.png" alt="image-20241202220545911" style="zoom:50%;" />

强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：

- `Cache-Control`，是一个相对时间；
- `Expires`，是一个绝对时间；

如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，**Cache-Control 的优先级高于 Expires** 。

Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：

- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；
- 浏览器再次请求访问服务器中的该资源时，会先**通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期**，如果没有，则使用该缓存，否则重新请求服务器；
- 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。



#### 协商缓存？

当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的响应码是 `304`，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412022205491.png" alt="img" style="zoom:50%;" />](https://camo.githubusercontent.com/6be3c3b07bff719ebe8432667c5adc9904a21c46794921f1f321fb108ebc62dc/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470312e312545342542432539382545352538432539362f254537254243253933254535254144253938657461672e706e67)

上图就是一个协商缓存的过程，所以**协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存**。

协商缓存可以基于两种头部来实现。

第一种：请求头部中的 `If-Modified-Since` 字段与响应头部中的 `Last-Modified` 字段实现，这两个字段的意思是：

- 响应头部中的 `Last-Modified`：标示这个响应资源的最后修改时间；
- 请求头部中的 `If-Modified-Since`：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。

第二种：请求头部中的 `If-None-Match` 字段与响应头部中的 `ETag` 字段，这两个字段的意思是：

- 响应头部中 `Etag`：唯一标识响应资源；
- 请求头部中的 `If-None-Match`：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。



第一种实现方式是**基于时间实现的**，第二种实现方式是**基于一个唯一标识实现的**，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。

如果在第一次请求资源的时候，服务端返回的 HTTP 响应头部同时有 Etag 和 Last-Modified 字段，那么客户端再下一次请求的时候，如果带上了 ETag 和 Last-Modified 字段信息给服务端，**这时 Etag 的优先级更高**，也就是服务端先会判断 Etag 是否变化了，如果 Etag 有变化就不用在判断 Last-Modified 了，如果 Etag 没有变化，然后再看 Last-Modified。

**为什么 ETag 的优先级更高？** 这是因为 ETag 主要能解决 Last-Modified 几个比较难以解决的问题：

1. 在没有修改文件内容情况下文件的最后修改时间可能也会改变，这会导致客户端认为这文件被改动了，从而重新请求；
2. 可能有些文件是在秒级以内修改的，`If-Modified-Since` 能检查到的粒度是秒级的，使用 Etag 就能够保证这种需求下客户端在 1 秒内能刷新多次；
3. 有些服务器不能精确获取文件的最后修改时间。

注意，**协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求**。



下图是强制缓存和协商缓存的工作流程：

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162318450.png" alt="img" style="zoom:67%;" />](https://camo.githubusercontent.com/918d1c7fb4205bc09ed134dacfbf974978b79175a58983d9d28bed2a40420a86/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f6e6574776f726b2f687474702f687474702545372542432539332545352541442539382e706e67)

当使用 ETag 字段实现的协商缓存的过程：

- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的；

- 当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期：

  - 如果没有过期，则直接使用本地缓存；
  - 如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识；

- 服务器再次收到请求后，

  会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较：

  - **如果值相等，则返回 304 Not Modified，不会返回资源**；
  - 如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识；

- 如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。



### HTTP/1.1 特性

#### HTTP/1.1 优点

*1. 简单*

HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，**易于理解**，降低了学习和使用的门槛。

*2. 灵活和易于扩展*

HTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**。

同时 HTTP 由于是工作在应用层（ `OSI` 第七层），则它**下层可以随意变化**，比如：

- HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层；
- HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。

*3. 应用广泛和跨平台*

#### HTTP/1.1 缺点

*1. 无状态双刃剑*

*2. 明文传输双刃剑*

*3. 不安全*

#### HTTP/1.1 性能

*1. 长连接*

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031609556.png" alt="image-20241202221605908" style="zoom: 50%;" />

1. **客户端发起请求**： 客户端在 HTTP 请求头中包含 `Connection: keep-alive`，告诉服务器它希望保持连接打开。
2. **服务器响应**： 服务器在响应头中也包含 `Connection: keep-alive`，表示同意保持连接打开，并且在响应结束后不关闭 TCP 连接。
3. **复用连接**： 之后，客户端可以继续使用这个连接发送后续的请求，而不需要重新建立新的连接。
4. **连接超时**： 为了防止连接长时间占用而没有数据传输，连接通常会在一段时间后超时关闭。如果超时时间到达，连接就会被服务器关闭，或者客户端主动关闭连接。

为了更好地管理长连接，客户端通常使用 **连接池**。连接池是一个事先创建好的连接缓存池，客户端可以从池中获取已建立好的连接，而不必每次都建立新的连接。

HTTP/1.1 默认支持长连接，且通过 `Connection: keep-alive` 头部进行控制。**HTTP/2 进一步改进了长连接的机制，通过多路复用**提高了性能。





*2. 管道网络传输*

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319121.png" alt="image-20241202221641770" style="zoom:50%;" />

即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以**减少整体的响应时间。**

但是**服务器必须按照接收请求的顺序发送对这些管道化请求的响应**。

如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住，这称为「队头堵塞」。

所以，**HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞**。



>实际上 HTTP/1.1 管道化技术不是默认开启，而且浏览器基本都没有支持，所以**后面所有文章讨论 HTTP/1.1 都是建立在没有使用管道化的前提**。大家知道有这个功能，但是没有被使用就行了。



*3. 队头阻塞*

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319473.png" alt="image-20241202221750381" style="zoom:50%;" />



### HTTP 与 HTTPS

#### SSL/TLS 协议加密

HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议

HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。

两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319643.png" alt="image-20241202221921027" style="zoom:50%;" />

> HTTPS 是如何解决上面的三个风险的？

- **混合加密**的方式实现信息的**机密性**，解决了**窃听的风险**。
- **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了**篡改的风险**。
- 将**服务器公钥**放入到**数字证书**中，解决了**冒充的风险**。



##### 1. 混合加密

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319905.png" alt="混合加密" style="zoom: 80%;" />](https://camo.githubusercontent.com/35607a8216b436b21b2d16897e80562cc1c9737709a5a41efc05d5f2286bddf5/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f485454502f32302d2545362542372542372545352539302538382545352538412541302545352541462538362e706e67)

HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式：

- 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。
- 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。



##### 2. 摘要算法 + 数字签名

计算机里会**用摘要算法（哈希函数）来计算出内容的哈希值**，也就是内容的「指纹」，这个**哈希值是唯一的，且无法通过哈希值推导出内容**。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319556.png" alt="img" style="zoom:50%;" />](https://camo.githubusercontent.com/228015d4722251bf6068f53c038bc3c7b88287af6276b629e41b492ceec5ef3c/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f485454502f2545362539312539382545382541362538312545372541452539372545362542332539352e706e67)

通过哈希算法可以确保内容不会被篡改，**但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明**。

那为了避免这种情况，计算机里会用**非对称加密算法**来解决，共有两个密钥：

- 一个是公钥，这个是可以公开给所有人的；
- 一个是私钥，这个必须由本人管理，不可泄露。

这两个密钥可以**双向加解密**的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容。

流程的不同，意味着目的也不相同：

- **公钥加密，私钥解密**。这个目的是为了**保证内容传输的安全**，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；
- **私钥加密，公钥解密**。这个目的是为了**保证消息不会被冒充**，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。

非对称加密的用途主要在于**通过「私钥加密，公钥解密」的方式，来确认消息的身份**，我们常说的**数字签名算法**，就是用的是这种方式，不过私钥加密内容不是内容本身，而是**对内容的哈希值加密**。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412022220882.png" alt="img" style="zoom:50%;" />](https://camo.githubusercontent.com/450d25a47a39e49d866d08a3fae9ded74cf7176b843a3d1acd8d59960a2e36f9/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f485454502f2545362539352542302545352541442539372545372541442542452545352539302538442e706e67)

私钥是由服务端保管，然后服务端会向客户端颁发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。



##### 3. 数字证书

前面我们知道：

- 可以通过哈希算法来保证消息的完整性；
- 可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）；

但是这还远远不够，**还缺少身份验证的环节**，万一公钥是被伪造的呢？

在计算机里，这个权威的机构就是 CA（数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319530.jpeg" alt="数子证书工作流程" style="zoom: 80%;" />](https://camo.githubusercontent.com/36d85cf928db3c2ac459649506ec79dece1c714d9a70bd266e81a552ebf8d3ca/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f485454502f32322d2545362539352542302545352541442539372545382541462538312545342542392541362545352542372541352545342542442539432545362542352538312545372541382538422e706e67)

通过数字证书的方式保证服务器公钥的身份，解决冒充的风险。



#### HTTPS 是如何建立连接的？其间交互了什么？

SSL/TLS 协议基本流程：

- 客户端向服务器索要并验证服务器的公钥。
- 双方协商生产「会话秘钥」。
- 双方采用「会话秘钥」进行加密通信。

前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。

TLS 的「握手阶段」涉及**四次**通信，使用不同的密钥交换算法，TLS 握手流程也会不一样的，现在常用的密钥交换算法有两种：[RSA 算法](https://xiaolincoding.com/network/2_http/https_rsa.html) 和 [ECDHE 算法](https://xiaolincoding.com/network/2_http/https_ecdhe.html)。

> **详细见RSA算法和ECDHE算法**  [HTTPS RSA 握手解析](https://xiaolincoding.com/network/2_http/https_rsa.html)  [HTTPS ECDHE 握手解析](https://xiaolincoding.com/network/2_http/https_ecdhe.html#离散对数)



#### HTTPS 的应用数据是如何保证完整性的？

TLS 在实现上分为**握手协议**和**记录协议**两层：

- TLS 握手协议就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）；
- TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议；

TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证，过程如下图：

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319748.png" alt="image-20241202223748713" style="zoom:50%;" />

记录协议完成后，最终的报文数据将传递到传输控制协议 (TCP) 层进行传输。

> 如果你想详细了解记录协议是如何分片、压缩、计算 MAC 值、分组加密，可以看这篇：[理解 SSL/TLS 系列 (四) 记录协议](https://blog.csdn.net/zhanyiwp/article/details/105627799)



#### HTTPS 一定安全可靠吗？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412022240516.png" alt="image-20241202224041362" style="zoom: 50%;" />

但是要发生这种场景是有前提的，前提是用户点击接受了中间人服务器的证书。

中间人服务器与客户端在 TLS 握手过程中，实际上发送了自己伪造的证书给浏览器，而这个伪造的证书是能被浏览器（客户端）识别出是非法的，于是就会提醒用户该证书存在问题。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319423.png" alt="image-20241202224128416" style="zoom:50%;" />

**HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全**。



> 为什么抓包工具能截取 HTTPS 数据？

很多抓包工具 之所以可以明文看到 HTTPS 数据，工作原理与中间人一致的。

对于 HTTPS 连接来说，中间人要满足以下两点，才能实现真正的明文代理：

1. 中间人，作为客户端与真实服务端建立连接这一步不会有问题，因为服务端不会校验客户端的身份；
2. 中间人，作为服务端与真实客户端建立连接，这里会有客户端信任服务端的问题，也就是服务端必须有对应域名的私钥；

中间人要拿到私钥只能通过如下方式：

1. 去网站服务端拿到私钥；
2. 去 CA 处拿域名签发私钥；
3. 自己签发受浏览器信任的证书；

不用解释，抓包工具只能使用第三种方式取得中间人的身份。

因此使用抓包工具进行 HTTPS 抓包的时候，抓包工具会生成根证书，导入到客户端系统的 受信任的根证书列表 中，这里的根证书实际上起认证中心（CA）的作用。

随后抓包工具使用该根证书签发域名的证书，因为根证书受信任，域名的证书同样会被浏览器信任。也就是抓包工具给自己创建了一个认证中心 CA，客户端拿着中间人（抓包工具）签发的证书去中间人（抓包工具）自己的 CA 做认证，这个证书当然被认为是有效的。



> 如何避免被中间人抓取数据？

我们要保证自己电脑的安全，不要被病毒乘虚而入，而且也不要点击任何证书非法的网站，这样 HTTPS 数据就不会被中间人截取到了。

当然，我们还可以通过 **HTTPS 双向认证**来避免这种问题。

一般我们的 HTTPS 是单向认证，客户端只会验证了服务端的身份，但是服务端并不会验证客户端的身份。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319927.png" alt="img" style="zoom:50%;" />](https://camo.githubusercontent.com/3a8bd817f49762a6b2e2e2c35aa2ed086290f7df5991393eeb2568feda883866/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f6e6574776f726b2f687474702f2545352538462538432545352539302539312545382541452541342545382541462538312e706e67)

如果用了双向认证方式，不仅客户端会验证服务端的身份，而且服务端也会验证客户端的身份。服务端一旦验证到请求自己的客户端为不可信任的，服务端就拒绝继续通信，客户端如果发现服务端为不可信任的，那么也中止通信。



### HTTP/1.1、HTTP/2、HTTP/3 演变

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412022245286.png" alt="image-20241202224518050" style="zoom: 67%;" />



#### HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

HTTP/1.1 相比 HTTP/1.0 性能上的改进：

- 使用**长连接**的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持**管道**（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

但 HTTP/1.1 还是有性能瓶颈：

- 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
- 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
- 没有请求优先级控制；
- 请求只能从客户端开始，服务器只能被动响应。



#### HTTP/2 做了什么优化？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319519.png" alt="image-20241202230212994" style="zoom: 67%;" />

HTTP/2 相比 HTTP/1.1 性能上的改进：

- **头部压缩**
- **二进制格式**
- **并发传输（Stream传输）**
- **服务器主动推送资源**

##### 1、头部压缩

**压缩头**（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的部分**。

**HPACK算法**：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。



##### 2、二进制格式

**头信息帧（Headers Frame）和数据帧（Data Frame）**。

**增加了数据传输的效率**

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319126.png" alt="image-20241202224736114" style="zoom:50%;" />



##### 3、并发传输

HTTP/1.1 的实现是基于请求 - 响应模型的，造成了**队头阻塞**的问题

而 HTTP/2 引出了 **Stream 概念**，多个 Stream 复用在一条 TCP 连接。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319727.png" alt="image-20241202225506228" style="zoom: 67%;" />

**针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream，也就是 HTTP/2 可以并行交错地发送请求和响应**。



##### 4、服务器推送

HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以**主动**向客户端发送消息。

客户端和服务器**双方都可以建立 Stream**，Stream ID 也是有区别的，**客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。**

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031610476.png" alt="image-20241202225713398" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319200.png" alt="image-20241202225729574" style="zoom: 67%;" />



##### HTTP/2 缺陷

HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。

**HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。**

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319380.jpeg" alt="img" style="zoom: 80%;" />](https://camo.githubusercontent.com/9cbe3e5d12d131ae1359ad4416f6e2f6b475bc1ac698d9b4e1e247469f30a5c3/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f6e6574776f726b2f717569632f68747470322545392539382542422545352541312539452e6a706567)

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319112.png" alt="image-20241202225926880" style="zoom:50%;" />

一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的**所有的 HTTP 请求都必须等待这个丢了的包被重传回来**。



#### HTTP/3 做了哪些优化？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319811.png" alt="image-20241202230200436" style="zoom:67%;" />

大家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。

QUIC 有以下 3 个特点。

- **无队头阻塞**
- **更快的连接建立**
- **连接迁移**



##### 1、无队头阻塞

QUIC 有自己的一套机制可以保证传输的可靠性的。**当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题**。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。Stream 可以认为就是一条 HTTP 请求。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319025.png" alt="image-20241202230359498" style="zoom: 50%;" />



##### 2、更快的连接建立

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031610832.png" alt="image-20241202230445294" style="zoom: 80%;" />



<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031610903.png" alt="image-20241202230508555" style="zoom: 50%;" />



##### 3、连接迁移

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。

[![TCP 四元组](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319590.png)](https://camo.githubusercontent.com/39c54e4e60de15cad8fd57b4a15a192305adbd7da66c19140013c73ff4882434/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c79396a5a473475616e4e6b5a577870646e4975626d56304c32646f4c336870595739736157356a6232526c6369394a6257466e5a556876633351794c7956464f435642525356424d5356464e795642525355354e7956464e69553551795643515356464e795643524355354d5356464e7956435169553551793955513141744a5555304a5549344a5467354a5555324a5546444a5545784a5555324a5468474a5545784a5555324a5467354a5468434a5555314a546b794a5468444a5555314a546c434a546c434a5555324a5546444a5545784a5555324a5468444a5545314a5555324a5467354a5468434c7a45774c6d70775a773f782d6f73732d70726f636573733d696d6167652f666f726d61742c706e67)

那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。



而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID** 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

所以，QUIC 是一个在 UDP 之上的**伪** TCP + TLS + HTTP/2 的多路复用的协议。

QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于 UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP 包，然后被丢弃。















































# 三、TCP

## TCP基本认识

### TCP 头格式

<img src="C:/Users/raosirui/AppData/Roaming/Typora/typora-user-images/image-20241202231625691.png" alt="image-20241202231625691" style="zoom:50%;" />

**序列号**：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。**用来解决网络包乱序问题。**

**确认应答号**：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决丢包的问题。**

**控制位：**

- *ACK*：该位为 `1` 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 `SYN` 包之外该位必须设置为 `1` 。
- *RST*：该位为 `1` 时，表示 TCP 连接中出现异常必须强制断开连接。
- *SYN*：该位为 `1` 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
- *FIN*：该位为 `1` 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位为 1 的 TCP 段。



### TCP特性：面向连接的、可靠的、基于字节流

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319848.png" alt="image-20241202231806056" style="zoom: 80%;" />

- **面向连接**：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；
- **可靠的**：无论网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；
- **字节流**：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。



### TCP 连接

**TCP 连接：用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 Socket、序列号和窗口大小称为连接**

建立一个 TCP 连接是需要客户端与服务端达成上述三个信息的共识。

- **Socket**：由 IP 地址和端口号组成
- **序列号**：用来解决乱序问题等
- **窗口大小**：用来做流量控制



### 唯一确定一个 TCP 连接：四元组

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319469.png" alt="image-20241202232040957" style="zoom:50%;" />

源地址和目的地址的字段（32 位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。

源端口和目的端口的字段（16 位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程。



<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319142.png" alt="image-20241202232225450" style="zoom: 67%;" />



### UDP 和 TCP 有什么区别呢？分别的应用场景是？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319294.png" alt="image-20241203094009791" style="zoom:50%;" />

UDP头部只有 8 个字节（64 位）

校验和：校验和是为了提供可靠的 UDP ⾸部和数据⽽设计，防⽌收到在⽹络传输中受损的 UDP 包。



**TCP 和 UDP 区别：**

*1. 连接*

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

*2. 服务对象*

- TCP 是一对一
- UDP 支持一对一、一对多、多对多

*3. 可靠性*

- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。
- UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议，具体可以参见这篇文章：[如何基于 UDP 协议实现可靠传输？](https://xiaolincoding.com/network/3_tcp/quic.html)

*4. 拥塞控制、流量控制*

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有

*5. 首部开销*

- TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

*6. 传输方式*

- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

*7. 分片不同*

- TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。



**TCP 和 UDP 应用场景：**

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- `FTP` 文件传输；
- HTTP / HTTPS；

由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 `DNS` 、`SNMP` 等；
- 视频、音频等多媒体通信；
- 广播通信；



> 为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？

原因是 TCP 有**可变长**的「选项」字段，而 UDP 头部长度则是**不会变化**的，无需多一个字段去记录 UDP 的首部长度。



> 为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？

TCP的包长度:

![image-20241203094420573](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319964.png)

UDP的包长度是是否冗余？

- 第一种说法：因为为了网络设备硬件设计和处理方便，首部长度需要是 `4` 字节的整数倍。如果去掉 UDP 的「包长度」字段，那 UDP 首部长度就不是 `4` 字节的整数倍了，所以我觉得这可能是为了补全 UDP 首部长度是 `4` 字节的整数倍，才补充了「包长度」字段。
- 第二种说法：如今的 UDP 协议是基于 IP 协议发展的，而当年可能并非如此，依赖的可能是别的不提供自身报文长度或首部长度的网络层协议，因此 UDP 报文首部需要有长度字段以供计算。



### TCP 和 UDP 可以使用同一个端口吗？

TCP/UDP 各自的端口号也相互独立，如 TCP 有一个 80 号端口，UDP 也可以有一个 80 号端口，二者并不冲突。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319597.png" alt="image-20241203094553458" style="zoom:50%;" />





## TCP 连接建立

### TCP三次握手

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412030947171.png" alt="image-20241203094743993" style="zoom: 33%;" />



- 一开始，客户端和服务端都处于 `CLOSE` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412030949829.jpeg" alt="第一个报文 —— SYN 报文" style="zoom:50%;" />](https://camo.githubusercontent.com/9c6cd948ad05c99aaef84b0a24b035b5a7a7f1354b27eead05c0b4887cf00425/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c79396a5a473475616e4e6b5a577870646e4975626d56304c32646f4c336870595739736157356a6232526c6369394a6257466e5a556876633351794c7956464f435642525356424d5356464e795642525355354e7956464e69553551795643515356464e795643524355354d5356464e7956435169553551793955513141744a5555304a5549344a5467354a5555324a5546444a5545784a5555324a5468474a5545784a5555324a5467354a5468434a5555314a546b794a5468444a5555314a546c434a546c434a5555324a5546444a5545784a5555324a5468444a5545314a5555324a5467354a5468434c7a45314c6d70775a773f782d6f73732d70726f636573733d696d6167652f666f726d61742c706e67)

- 客户端会随机初始化序号（`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1`，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319095.png" alt="第二个报文 —— SYN + ACK 报文" style="zoom:50%;" />](https://camo.githubusercontent.com/b054aab6a99b00291a930a7b7e3e48fbc6d1084587b5e662bd1fd8e906c60bb4/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c79396a5a473475616e4e6b5a577870646e4975626d56304c32646f4c336870595739736157356a6232526c6369394a6257466e5a556876633351794c7956464f435642525356424d5356464e795642525355354e7956464e69553551795643515356464e795643524355354d5356464e7956435169553551793955513141744a5555304a5549344a5467354a5555324a5546444a5545784a5555324a5468474a5545784a5555324a5467354a5468434a5555314a546b794a5468444a5555314a546c434a546c434a5555324a5546444a5545784a5555324a5468444a5545314a5555324a5467354a5468434c7a45324c6d70775a773f782d6f73732d70726f636573733d696d6167652f666f726d61742c706e67)

- 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态。

[<img src="https://camo.githubusercontent.com/cbaa8bab303bf3abcf8162f975455e5582ed9c7638526af666f59214a6b40535/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c79396a5a473475616e4e6b5a577870646e4975626d56304c32646f4c336870595739736157356a6232526c6369394a6257466e5a556876633351794c7956464f435642525356424d5356464e795642525355354e7956464e69553551795643515356464e795643524355354d5356464e7956435169553551793955513141744a5555304a5549344a5467354a5555324a5546444a5545784a5555324a5468474a5545784a5555324a5467354a5468434a5555314a546b794a5468444a5555314a546c434a546c434a5555324a5546444a5545784a5555324a5468444a5545314a5555324a5467354a5468434c7a45334c6d70775a773f782d6f73732d70726f636573733d696d6167652f666f726d61742c706e67" alt="第三个报文 —— ACK 报文" style="zoom:50%;" />](https://camo.githubusercontent.com/cbaa8bab303bf3abcf8162f975455e5582ed9c7638526af666f59214a6b40535/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c79396a5a473475616e4e6b5a577870646e4975626d56304c32646f4c336870595739736157356a6232526c6369394a6257466e5a556876633351794c7956464f435642525356424d5356464e795642525355354e7956464e69553551795643515356464e795643524355354d5356464e7956435169553551793955513141744a5555304a5549344a5467354a5555324a5546444a5545784a5555324a5468474a5545784a5555324a5467354a5468434a5555314a546b794a5468444a5555314a546c434a546c434a5555324a5546444a5545784a5555324a5468444a5545314a5555324a5467354a5468434c7a45334c6d70775a773f782d6f73732d70726f636573733d696d6167652f666f726d61742c706e67)

- 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 `ESTABLISHED` 状态。
- 服务端收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。



从上面的过程可以发现**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**，这也是面试常问的题。

一旦完成三次握手，双方都处于 `ESTABLISHED` 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。



### :star:为什么是三次握手？不是两次、四次？

**TCP 连接定义**：用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 **Socket、序列号和窗口大小**称为连接。

所以，重要的是**为什么三次握手才可以初始化 Socket、序列号和窗口大小并建立 TCP 连接。**

接下来，以三个方面分析三次握手的原因：

- 三次握手才可以**阻止重复历史连接的初始化**（**主要原因**）
- 三次握手才可以**同步双方的初始序列号**
- 三次握手才可以**避免资源浪费**



#### 1、避免历史连接

> [!IMPORTANT]
>
> **如果客户端收到旧的连接，会比较Seq是否是正确连接，错误则给服务端发生送一个RST终止重试，直到收到新的正确连接则建立成功，假如只有两次连接则不能判断是否正确。**



三次握手的**首要原因是为了防止旧的重复连接初始化造成混乱。**

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319712.png" alt="image-20241203095441981" style="zoom:50%;" />

上述中的「旧 SYN 报文」称为历史连接，TCP 使用三次握手建立连接的**最主要原因就是防止「历史连接」初始化了连接**。



**如果是两次握手连接，就无法阻止历史连接**，那为什么 TCP 两次握手为什么无法阻止历史连接呢？

我先直接说结论，主要是因为**在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费**。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319043.png" alt="image-20241203095847153" style="zoom:50%;" />

可以看到，如果采用两次握手建立 TCP 连接的场景下，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据，妥妥地浪费了服务端的资源。

因此，**要解决这种现象，最好就是在服务端发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就需要三次握手**。



#### 2、同步双方初始序列号

序列号是可靠传输的一个关键因素，它的作用：

- 接收方可以去除重复的数据；
- 接收方可以根据数据包的序列号按序接收；
- 可以标识发送出去的数据包中，哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319476.png" alt="image-20241203100153379" style="zoom: 33%;" />

**而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。**



#### 3、避免资源浪费

二次握手时：如果客户端发送的 `SYN` 报文在网络中阻塞了，重复发送多次 `SYN` 报文，那么服务端在收到请求后就会**建立多个冗余的无效连接，造成不必要的资源浪费。**

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319622.png" alt="image-20241203100323960" style="zoom: 50%;" />



#### 总结

不使用「两次握手」和「四次握手」的原因：

- 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。



### 为什么每次建立 TCP 连接时，初始化的序列号都要求不一样？

主要原因有两个方面：

- 为了防止历史报文被下一个相同四元组的连接接收（主要方面）；
- 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；



假设TCP连接初始化序列号一样：

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031008576.png" alt="image-20241203100802110" style="zoom:50%;" />



如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了历史报文，比如下图：

**还需要加上时间戳避免重复**

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319525.png" alt="image-20241203100812727" style="zoom:50%;" />





### 初始序列号 ISN 是如何随机产生的？

**基于四元组的Hash和时间戳结合而成**

起始 `ISN` 是基于时钟的，每 4 微秒 + 1，转一圈要 4.55 个小时。

RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。

- `M` 是一个**计时器**，这个计时器每隔 4 微秒加 1。
- `F` 是一个 **Hash 算法**，根据**源 IP、目的 IP、源端口、目的端口**生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。





### 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202503162319357.png" alt="image-20241203101111257" style="zoom:50%;" />

- `MTU`：一个网络包的最大长度，以太网中一般为 `1500` 字节；
- `MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；



如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，**那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传**。

因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。



当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU，自然也就不用 IP 分片了。

经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率。





### 第一次握手丢失了，会发生什么？

服务端不会进行任何的动作，而客户端由于⼀段时间内没有收到服务端发来的确认报文，等待一段时间 后会重新发送 SYN 报⽂，

**重传的 SYN 报文的序列号都是一样的**。如果仍然没有回应，会重复这个过程，**每次超时的时间是上一次的 2 倍**。

直到发送次数超过最大重传次数限制，就会返回连接建立失败。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031018389.png" alt="image-20241203101806162" style="zoom:50%;" />



### 第二次握手丢失了，会发生什么？

因为第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是**客户端就会触发超时重传机制，重传 SYN 报文**。

那么，如果第二次握手丢失了，服务端就收不到第三次握手，于是**服务端这边会触发超时重传机制，重传 SYN-ACK 报文**。

客户端会继续重传，直到次数限制；而服务端此时会**阻塞在 accept()处**，等待客户端发送 ACK 报文



<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031020952.png" alt="image-20241203102044801" style="zoom:50%;" />





### 第三次握手丢失了，会发生什么？

因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。

注意，**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**。





### 半连接队列和 SYN Flood 攻击

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列，**第一次握手完进入SYN队列**；
- 全连接队列，也称 accept 队列，**三次握手完进入Accept队列**；

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031028316.png" alt="image-20241203102839137" style="zoom:50%;" />



**SYN Blood攻击方式**最直接的表现就会把 TCP 半连接队列打满，这样**当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃**，导致客户端无法和服务端建立连接。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031032282.png" alt="image-20241203103202044" style="zoom: 33%;" />

避免 SYN 攻击方式，可以有以下四种方法：

- 调大 netdev_max_backlog；
- 增大 TCP 半连接队列；
- 开启 tcp_syncookies；

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031034452.png" alt="image-20241203103427221" style="zoom: 50%;" />

- 减少 SYN+ACK 重传次数







## TCP 连接断开

### TCP 四次挥手过程是怎样的？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031036289.png" alt="image-20241203103655100" style="zoom:50%;" />

**主动关闭连接的，才有 TIME_WAIT 状态。**





### 为什么挥手需要四次？

再来回顾下四次挥手双方发 `FIN` 包的过程，就能理解为什么需要四次了。

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，**服务端通常需要等待完成数据的发送和处理**，**所以服务端的 `ACK` 和 `FIN` 一般都会分开发送**，因此是需要四次挥手。

但是**在特定情况下，四次挥手是可以变成三次挥手的**，具体情况可以看这篇：[TCP 四次挥手，可以变成三次吗？](https://xiaolincoding.com/network/3_tcp/tcp_three_fin.html)





### 第一次挥手丢失了，会发生什么？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031041395.png" alt="image-20241203104138108" style="zoom:50%;" />

### 第二次挥手丢失了，会发生什么？

**ACK 报文是不会重传的**，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031045733.png" alt="image-20241203104528472" style="zoom:50%;" />





当客户端收到第二次挥手，也就是收到服务端发送的 ACK 报文后，客户端就会处于 `FIN_WAIT2` 状态，在这个状态需要等服务端发送第三次挥手，也就是服务端的 FIN 报文。

对于调用 close 关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭，如下图：

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031048575.png" alt="image-20241203104818286" style="zoom:50%;" />

但是注意，如果主动关闭方使用 **shutdown 函数**关闭连接，指定了只关闭发送方向，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的。

此时，如果主动关闭方一直没收到第三次挥手，那么主动关闭方的连接将会一直处于 `FIN_WAIT2` 状态（`tcp_fin_timeout` 无法控制 shutdown 关闭的连接）。如下图：

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031049859.png" alt="image-20241203104919650" style="zoom:50%;" />



### 第三次挥手丢失了，会发生什么？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031050646.png" alt="image-20241203105028358" style="zoom:50%;" />





### 第四次挥手丢失了，会发生什么？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031051643.png" alt="image-20241203105100398" style="zoom:50%;" />



### 为什么 TIME_WAIT 等待的时间是 2MSL？

**`MSL` 是 Maximum Segment Lifetime，报文最大生存时间**

MSL 与 TTL 的区别：MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。

**TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了**。

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是：网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以**一来一回需要等待 2 倍的时间**。

可以看到 **2MSL 时长** 这其实是相当于**至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一

`2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。





### 为什么需要 TIME_WAIT 状态？

主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。

需要 TIME-WAIT 状态，主要是两个原因：

- 防止历史连接中的数据，被后面相同四元组的连接错误的接收；
- 保证「被动关闭连接」的一方，能被正确的关闭；



#### 1、防止历史连接中的数据

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031102541.png" alt="image-20241203110204267" style="zoom:50%;" />

 TCP 设计了 TIME_WAIT 状态，状态会持续 `2MSL` 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。**



#### 2、保证「被动关闭连接」的一方，能被正确的关闭:star:

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031102569.png" alt="image-20241203110259165" style="zoom: 33%;" />

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031103987.png" alt="image-20241203110335800" style="zoom:33%;" />



### TIME_WAIT 过多有什么危害？

过多的 TIME-WAIT 状态主要的危害有两种：

- 第一是占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；
- 第二是占用端口资源，端口资源也是有限的，一般可以开启的端口为 `32768～61000`，也可以通过 `net.ipv4.ip_local_port_range`参数指定范围。

**如果客户端（主动发起关闭连接方）的 TIME_WAIT 状态过多**，占满了所有端口资源，那么就无法对**「目的 IP+ 目的 PORT」都一样**的服务端发起连接了，但是被使用的端口，还是可以继续对另外一个服务端发起连接的。

**如果服务端（主动发起关闭连接方）的 TIME_WAIT 状态过多**，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。



### 如何优化 TIME_WAIT？

这里给出优化 TIME-WAIT 的几个方式，都是有利有弊：

- 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；

	**复用处于 TIME_WAIT 的 socket 为新的连接所用**，后者为TCP **时间戳**的支持

- net.ipv4.tcp_max_tw_buckets

	**当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置**，

- 程序中使用 SO_LINGER，应用强制使用 RST 关闭。（危险）

	调用`close`后，会立该发送一个`RST`标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了`TIME_WAIT`状态，直接关闭。





### 服务器出现大量 TIME_WAIT 状态的原因有哪些？

> [!IMPORTANT]
>
> **主要从长连接入手**
>
> 1. **HTTP 没有使用长连接**
> 2. **HTTP 长连接超时**
> 3. **HTTP 长连接的请求数量达到上限**

TIME_WAIT 状态是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接。

**什么场景下服务端会主动断开连接呢？**

- 第一个场景：**HTTP 没有使用长连接**

**只要客户端和服务端任意一方的 HTTP header 中有 `Connection:close` 信息，那么就无法使用 HTTP 长连接的机制**。

因为任意一方没有开启 HTTP Keep-Alive，都会导致服务端在处理完一个 HTTP 请求后，就主动关闭连接，此时服务端上就会出现大量的 TIME_WAIT 状态的连接。

解决的方式：让客户端和服务端都开启 HTTP Keep-Alive 机制。



- 第二个场景：**HTTP 长连接超时**

假设设置了 HTTP 长连接的超时时间是 60 秒，nginx 就会启动一个「定时器」，**如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接**。

可以往网络问题的方向排查，比如是否是因为网络问题，导致客户端发送的数据一直没有被服务端接收到，以至于 HTTP 长连接超时。



- 第三个场景：**HTTP 长连接的请求数量达到上限**

**如果达到这个参数设置的最大值时，则 nginx 会主动关闭这个长连接**，

**对于一些 QPS 比较高的场景，比如超过 10000 QPS，甚至达到 30000 , 50000 甚至更高，如果 keepalive_requests 参数值是 100，这时候就 nginx 就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态**。

针对这个场景下，解决的方式也很简单，调大 nginx 的 keepalive_requests 参数就行。





### 服务器出现大量 CLOSE_WAIT 状态的原因有哪些？

**当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接**。



我们先来分析一个普通的 TCP 服务端的流程：

1. 创建服务端 socket，bind 绑定端口、listen 监听端口
2. 将服务端 socket 注册到 epoll
3. epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket
4. 将已连接的 socket 注册到 epoll
5. epoll_wait 等待事件发生
6. 对方连接关闭时，我方调用 close



可能导致服务端没有调用 close 函数的原因，如下。

**第一个原因**：第 2 步没有做，没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个事件，也就无法获取到已连接的 socket，那服务端自然就没机会对 socket 调用 close 函数了。

不过这种原因发生的概率比较小，这种属于明显的代码逻辑 bug，在前期 read view 阶段就能发现的了。

**第二个原因**：第 3 步没有做，有新连接到来时没有调用 accpet 获取该连接的 socket，导致当有大量的客户端主动断开了连接，而服务端没机会对这些 socket 调用 close 函数，从而导致服务端出现大量 CLOSE_WAIT 状态的连接。

发生这种情况可能是因为服务端在执行 accpet 函数之前，代码卡在某一个逻辑或者提前抛出了异常。

**第三个原因**：第 4 步没有做，通过 accpet 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，那服务端就没机会调用 close 函数了。

发生这种情况可能是因为服务端在将已连接的 socket 注册到 epoll 之前，代码卡在某一个逻辑或者提前抛出了异常。之前看到过别人解决 close_wait 问题的实践文章，感兴趣的可以看看：[一次 Netty 代码不健壮导致的大量 CLOSE_WAIT 连接原因分析](https://mp.weixin.qq.com/s?__biz=MzU3Njk0MTc3Ng==&mid=2247486020&idx=1&sn=f7cf41aec28e2e10a46228a64b1c0a5c&scene=21#wechat_redirect)

**第四个原因**：第 6 步没有做，当发现客户端关闭连接后，服务端没有执行 close 函数，可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑，比如发生死锁等等。

可以发现，**当服务端出现大量 CLOSE_WAIT 状态的连接的时候，通常都是代码的问题，这时候我们需要针对具体的代码一步一步的进行排查和定位，主要分析的方向就是服务端为什么没有调用 close**。





### 如果已经建立了连接，但是客户端突然出现故障了怎么办？

TCP 搞了个**保活机制**，每隔一个时间间隔，发送一个探测报文，

若想使用 TCP 保活机制需要通过 socket 接口设置 `SO_KEEPALIVE` 选项才能够生效

TCP保活情况：

- 第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端，对端会正常响应，这样 **TCP 保活时间会被重置**
- 第二种，对端主机宕机并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，**会产生一个 RST 报文**，这样很快就会发现 TCP 连接已经被重置。
- 第三种，是对端主机宕机（*注意不是进程崩溃，进程崩溃后操作系统在回收进程资源的时候，会发送 FIN 报文，而主机宕机则是无法感知的，所以需要 TCP 保活机制来探测对方是不是发生了主机宕机*），或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。



TCP 保活的这个机制检测的时间是有点长，我们可以自己在应用层实现一个心跳机制。

比如，web 服务软件一般都会提供 `keepalive_timeout` 参数，用来指定 HTTP 长连接的超时时间。**定时器的时间一到，就会触发回调函数来释放该连接。**





### 如果已经建立了连接，但是服务端的进程崩溃会发生什么？

后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。

**在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手**。











## Socket 编程

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031141779.png" alt="image-20241203114122496" style="zoom:50%;" />

这里需要注意的是，服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。

所以，监听的 socket 和真正用来传送数据的 socket，是「两个」socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。



### listen 时候参数 backlog 的意义？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031143110.png" alt="image-20241203114317865" style="zoom: 50%;" />

```
int listen (int socketfd, int backlog)
```

- 参数一 socketfd 为 socketfd 文件描述符
- 参数二 backlog，这参数在历史版本有一定的变化

在早期 Linux 内核 backlog 是 SYN 队列大小，也就是未完成的队列大小。

在 Linux 内核 2.2 之后，backlog 变成 accept 队列，也就是已完成连接建立的队列长度，**所以现在通常认为 backlog 是 accept 队列。**

**但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 = min(backlog, somaxconn)。**





### accept 发生在三次握手的哪一步？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031144078.png" alt="image-20241203114436765" style="zoom: 33%;" />

**客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。**





### 客户端调用 close 了，连接是断开的流程是什么？

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031146194.png" alt="image-20241203114616902" style="zoom:33%;" />

这个 `EOF` 会被**放在已排队等候的其他已接收的数据之后**，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态；





### 没有 accept，能建立 TCP 连接吗？

**答案：**可以的**。**

accept 系统调用并不参与 TCP 三次握手过程，它只是负责从 TCP 全连接队列取出一个已经建立连接的 socket，用户层通过 accept 系统调用拿到了已经建立连接的 socket，就可以对该 socket 进行读写操作了。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031148203.png" alt="image-20241203114842039" style="zoom:50%;" />





### 没有 listen，能建立 TCP 连接吗？

答案：**可以的**。

客户端是可以自己连自己的形成连接（**TCP 自连接**），也可以两个客户端同时向对方发出请求建立连接（**TCP 同时打开**），这两个情况都有个共同点，就是**没有服务端参与，也就是没有 listen，就能 TCP 建立连接。**

更想了解这个问题，可以参考这篇文章：[服务端没有 listen，客户端发起连接建立，会发生什么？](https://xiaolincoding.com/network/3_tcp/tcp_no_listen.html)







## TCP 重传、滑动窗口、流量控制、拥塞控制

### 重传机制

接下来说说常见的重传机制：

- 超时重传
- 快速重传
- SACK
- D-SACK



#### 超时重传

TCP 会在以下两种情况发生超时重传：

- 数据包丢失
- 确认应答丢失

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031502037.png" alt="image-20241203150245821" style="zoom: 33%;" />

**RTT** 指的是**包的往返时间**。



**超时重传时间**是以 **RTO** （Retransmission Timeout 超时重传时间）表示。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031503130.png" alt="image-20241203150348841" style="zoom:50%;" />

**超时重传时间 RTO 的值应该略大于报文往返 RTT 的值**。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031504503.png" alt="image-20241203150427206" style="zoom:33%;" />

「报文往返 RTT 的值」是经常变化的，因为我们的网络也是时常变化的。也就因为「报文往返 RTT 的值」是经常波动变化的，所以「超时重传时间 RTO 的值」应该是一个**动态变化的值**。



如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**

也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。**

可以用「快速重传」机制来解决超时重发的时间等待。





#### 快速重传

TCP 还有另外一种**快速重传（Fast Retransmit）机制**，它**不以时间为驱动，而是以数据驱动重传**。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031507648.png" alt="image-20241203150704341" style="zoom:50%;" />

它依然面临着另外一个问题。就是**重传的时候，是重传一个，还是重传所有的问题。**为了解决不知道该重传哪些 TCP 报文，于是就有 `SACK` 方法。





#### SACK 方法

`SACK`（ Selective Acknowledgment）， **选择性确认**。

这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031508174.png" alt="image-20241203150858754" style="zoom: 50%;" />





#### Duplicate SACK

Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

**1、ACK 丢包**

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031510030.webp" alt="ACK 丢包" style="zoom: 67%;" />](https://camo.githubusercontent.com/df3b77312474bb58320fb447ce8c6656dc0563abca62e17fbff8a68f8fa3bf9c/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f7374322f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f5443502d2545352538462541462545392539442541302545372538392542392545362538302541372f31322e6a70673f696d6167655f70726f636573733d77617465726d61726b2c746578745f35595773354c795835592d333737796135624350357036585932396b6157356e2c747970655f5a6e70736448706f61772c785f31302c795f31302c675f73652c73697a655f32302c636f6c6f725f3030303043442c745f37302c66696c6c5f30)



**2、网络延时**

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031510947.webp" alt="网络延时" style="zoom:67%;" />](https://camo.githubusercontent.com/ae7c9054e82c196e9399919e8f369ad280e2fe6f06e12a97ecacc5f4b7d91534/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f7374322f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f5443502d2545352538462541462545392539442541302545372538392542392545362538302541372f31332e6a70673f696d6167655f70726f636573733d77617465726d61726b2c746578745f35595773354c795835592d333737796135624350357036585932396b6157356e2c747970655f5a6e70736448706f61772c785f31302c795f31302c675f73652c73697a655f32302c636f6c6f725f3030303043442c745f37302c66696c6c5f30)



可见，`D-SACK` 有这么几个好处：

1. **可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;**
2. **可以知道是不是「发送方」的数据包被网络延迟了;**
3. **可以知道网络中是不是把「发送方」的数据包给复制了;**









### 滑动窗口

窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。



#### 累计确认

只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫**累计确认**或者**累计应答**。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031514362.png" alt="image-20241203151410037" style="zoom: 50%;" />



通常窗口的大小是**由接收方的窗口大小来决定**的。

发送方发送的数据大小不能超过接收方的窗口大小，





#### 发送方滑动窗口

TCP 滑动窗口方案使用**三个指针**来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。

[![SND.WND, SND.UN, SND.NXT](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031516873.webp)](https://camo.githubusercontent.com/c5dc5845a03c7f3098fd1886a3e332720ef4a5723c03eed35f9a38ddc4d5430f/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f7374322f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f5443502d2545352538462541462545392539442541302545372538392542392545362538302541372f31392e6a70673f696d6167655f70726f636573733d77617465726d61726b2c746578745f35595773354c795835592d333737796135624350357036585932396b6157356e2c747970655f5a6e70736448706f61772c785f31302c795f31302c675f73652c73697a655f32302c636f6c6f725f3030303043442c745f37302c66696c6c5f30)





#### 接收方滑动窗口

其中三个接收部分，使用**两个指针**进行划分：

![image-20241203151910708](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031519070.png)



> 接收窗口和发送窗口的大小是相等的吗？

并不是完全相等，接收窗口的大小是**约等于**发送窗口的大小的。

因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。



### 流量控制

**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**



#### 操作系统缓冲区与滑动窗口的关系

![image-20241203152945812](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031529143.png)

可见最后窗口都收缩为 0 了，也就是发生了窗口关闭。当发送方可用窗口变为 0 时，发送方实际上会定时发送窗口探测报文，以便知道接收方的窗口是否发生了改变，这个内容后面会说，这里先简单提一下。





![image-20241203152929133](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031529320.png)

**为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。**



#### 窗口关闭

**如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。**

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031531456.png" alt="image-20241203153127167" style="zoom:50%;" />





为了解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**

如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。



<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031532203.png" alt="image-20241203153217984" style="zoom:50%;" />

如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 `RST` 报文来中断连接。



#### 糊涂窗口综合症

**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**。



于是，要解决糊涂窗口综合症，就要同时解决上面两个问题就可以了：

- 让接收方不通告小窗口给发送方
- 让发送方避免发送小数据



让接收方不通告小窗口呢？

##### 1、延迟确认

接收方通常的策略如下：

当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 `0`，也就阻止了发送方再发数据过来。

等到接收方处理了一些数据后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。



让发送方避免发送小数据呢？

##### 2、Nagle算法

发送方通常的策略如下：

使用 Nagle 算法，该算法的思路是延时处理，只有满足下面两个条件中的任意一个条件，才可以发送数据：

- 条件一：要等到可用窗口大小 >= `MSS` 并且 数据大小 >= `MSS`；
- 条件二：收到之前发送数据的 `ack` 回包；

只要上面两个条件都不满足，发送方一直在囤积数据，直到满足上面的发送条件。

Nagle 伪代码如下：

```
if 有数据要发送 {
    if 可用窗口大小 >= MSS and 可发送的数据 >= MSS {
    	立刻发送MSS大小的数据
    } else {
        if 有未确认的数据 {
            将数据放入缓存等待接收ACK
        } else {
            立刻发送数据
        }
    }
}
```



注意，如果接收方不能满足「不通告小窗口给发送方」，那么即使开了 Nagle 算法，也无法避免糊涂窗口综合症，因为如果对端 ACK 回复很快的话（达到 Nagle 算法的条件二），Nagle 算法就不会拼接太多的数据包，这种情况下依然会有小数据包的传输，网络总体的利用率依然很低。

所以，**接收方得满足「不通告小窗口给发送方」+ 发送方开启 Nagle 算法，才能避免糊涂窗口综合症**。

另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。





### 拥塞控制

流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。

**在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大……**

于是，就有了**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**



为了在「发送方」调节所要发送数据的量，定义了一个叫做「**拥塞窗口**」的概念。

> 什么是拥塞窗口？和发送窗口有什么关系呢？

**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。



我们在前面提到过发送窗口 `swnd` 和接收窗口 `rwnd` 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是

 **swnd = min(cwnd, rwnd)**

也就是拥塞窗口和接收窗口中的最小值。



拥塞窗口 `cwnd` 变化的规则：

- 只要网络中没有出现拥塞，`cwnd` 就会增大；
- 但网络中出现了拥塞，`cwnd` 就减少；



> 那么怎么知道当前网络是否出现了拥塞呢？

其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**

> 拥塞控制有哪些控制算法？

拥塞控制主要是四个算法：

- 慢启动
- 拥塞避免
- 拥塞发生
- 快速恢复



#### 慢启动

有一个叫慢启动门限 `ssthresh` （slow start threshold）状态变量。

- 当 `cwnd` < `ssthresh` 时，使用慢启动算法。
- 当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031541703.png" alt="image-20241203154121396" style="zoom: 33%;" />







#### 拥塞避免算法

当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法。

进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031542959.png" alt="image-20241203154208731" style="zoom:33%;" />

就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。

当触发了重传机制，也就进入了「拥塞发生算法」。



#### 拥塞发生

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：

- 超时重传
- 快速重传

这两种使用的拥塞发生算法是不同的，接下来分别来说说。



##### 1、发生超时重传的拥塞发生算法

当发生了「超时重传」，则就会使用拥塞发生算法。

这个时候，ssthresh 和 cwnd 的值会发生变化：

- `ssthresh` 设为 `cwnd/2`，
- `cwnd` 重置为 `1` （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031546980.png" alt="image-20241203154631550" style="zoom: 33%;" />



##### 2、发生快速重传的拥塞发生算法

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;
- 进入快速恢复算法



#### 快速恢复

正如前面所说，进入快速恢复之前，`cwnd` 和 `ssthresh` 已被更新了：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;

然后，进入快速恢复算法如下：

- 拥塞窗口 `cwnd = ssthresh + 3` （3 的意思是确认有 3 个数据包被收到了）；
- 重传丢失的数据包；
- 如果再收到重复的 ACK，那么 cwnd 增加 1；
- 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；

![image-20241203154823766](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031548032.png)



















# 四、网络层

## IP 基础认识

> 网络层与数据链路层有什么关系呢？

有的小伙伴分不清 IP（网络层）和 MAC（数据链路层）之间的区别和关系。

其实很容易区分，在上面我们知道 IP 的作用是主机之间通信用的，而 **MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。**

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031151081.png" alt="image-20241203115120798" style="zoom:50%;" />

**计算机网络中也需要「数据链路层」和「网络层」这个分层才能实现向最终目标地址的通信。**

**源 IP 地址和目标 IP 地址在传输过程中是不会变化的，只有源 MAC 地址和目标 MAC 一直在变化。**



## IP 地址的基础知识

### IP 地址的分类

分为ABCDE五类

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031152439.png" alt="image-20241203115245283" style="zoom:50%;" />

- 主机号全为 1 指定某个网络下的所有主机，用于广播

		广播地址用于在**同一个链路中相互连接的主机之间发送数据包**。
		
		**在本网络内广播的叫做本地广播**。
		
		**在不同网络之间的广播叫做直接广播**。

- 主机号全为 0 指定某个网络



### 无分类地址 CIDR

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031155087.png" alt="image-20241203115555949" style="zoom:50%;" />



### 公有 IP 地址与私有 IP 地址

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031157586.png" alt="image-20241203115749412" style="zoom:50%;" />

> 公有 IP 地址由谁管理呢？

私有 IP 地址通常是内部的 IT 人员管理，公有 IP 地址是由 `ICANN` 组织管理，中文叫「互联网名称与数字地址分配机构」。

IANA 是 ICANN 的其中一个机构，它负责分配互联网 IP 地址，是按洲的方式层层分配。



### IP 地址与路由控制

P 地址的**网络地址**这一部分是用于进行路由控制。

在发送 IP 包时从路由控制表中找到与该地址具有**相同网络地址**的记录。如果路由控制表中存在多条相同网络地址的记录，就选择相同位数最多的网络地址，也就是最长匹配。



> 环回地址是不会流向网络

环回地址是在同一台计算机上的程序之间进行网络通信时所使用的一个默认地址。

计算机使用一个特殊的 IP 地址 **127.0.0.1 作为环回地址**。与该地址具有相同意义的是一个叫做 `localhost` 的主机名。使用这个 IP 或主机名时，数据包不会流向网络。





### IP 分片与重组

每种数据链路的最大传输单元 `MTU` 都是不相同的，如 FDDI 数据链路 MTU 4352、以太网的 MTU 是 1500 字节等。

是因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。



经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，路由器是不会进行重组的。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031241595.png" alt="image-20241203124129284" style="zoom:50%;" />

在分片传输中，一旦某个分片丢失，则会造成整个 IP 数据报作废，所以 TCP 引入了 `MSS` 也就是在 TCP 层进行分片不由 IP 层分片，那么对于 UDP 我们尽量不要发送一个大于 `MTU` 的数据报文。





### IPv6 基本认识

Pv6 不仅仅只是可分配的地址变多了，它还有非常多的亮点。

- IPv6 可自动配置，即使没有 DHCP 服务器也可以实现自动分配 IP 地址，真是**便捷到即插即用**啊。
- IPv6 包头包首部长度采用固定的值 `40` 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大大**提高了传输的性能**。
- IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大**提升了安全性**。
- **...** （由你发现更多的亮点）

![image-20241203124252191](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031242346.png)

IPv6 的地址主要有以下类型地址：

- 单播地址，用于一对一的通信
- 组播地址，用于一对多的通信
- 任播地址，用于通信最近的节点，最近的节点是由路由协议决定
- 没有广播地址



> IPv6 单播地址类型

对于一对一通信的 IPv6 地址，主要划分了三类单播地址，每类地址的有效范围都不同。

- 在同一链路单播通信，不经过路由器，可以使用**链路本地单播地址**，IPv4 没有此类型
- 在内网里单播通信，可以使用**唯一本地地址**，相当于 IPv4 的私有 IP
- 在互联网通信，可以使用**全局单播地址**，相当于 IPv4 的公有 IP





### IPv4 首部与 IPv6 首部

![image-20241203124510748](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031245042.png)

IPv6 相比 IPv4 的首部改进：

- **取消了首部校验和字段。** 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。
- **取消了分片/重新组装相关字段。** 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提高了路由器转发的速度。
- **取消选项字段。** 选项字段不再是标准 IP 首部的一部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上。删除该选项字段使的 IPv6 的首部成为固定长度的 `40` 字节。





## IP 协议相关技术

跟 IP 协议相关的技术也不少，接下来说说与 IP 协议相关的重要且常见的技术。

- DNS 域名解析
- ARP 与 RARP 协议
- DHCP 动态获取 IP 地址
- NAT 网络地址转换
- ICMP 互联网控制报文协议
- IGMP 因特网组管理协



### DNS

在域名中，**越靠右**的位置表示其层级**越高**。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031247260.png" alt="image-20241203124746874" style="zoom:50%;" />



### ARP

由于主机的路由表中可以找到下一跳的 IP 地址，所以可以通过 **ARP 协议**，求得下一跳的 MAC 地址。

> 那么 ARP 又是如何知道对方 MAC 地址的呢？

简单地说，ARP 是借助 **ARP 请求与 ARP 响应**两种类型的包确定 MAC 地址的。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031249235.jpeg" alt="ARP 广播" style="zoom: 67%;" />](https://camo.githubusercontent.com/fbee0929ac9bf5433bf3b8c5004b13bfca57ec4c523b3d76b66deabb01d941be/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f49502f33342e6a7067)

- 主机会通过**广播发送 ARP 请求**，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。

  如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 **ARP 响应包**返回给主机。



操作系统会把ARP的MAC**缓存**起来



> RARP 协议你知道是什么吗？

ARP 协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是**已知 MAC 地址求 IP 地址**。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031254744.png" alt="image-20241203125429479" style="zoom:50%;" />





### DHCP

**动态主机配置协议**

DHCP 在生活中我们是很常见的了，我们的电脑通常都是通过 DHCP 动态获取 IP 地址，大大省去了配 IP 信息繁琐的过程。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031444500.png" alt="image-20241203144405186" style="zoom: 67%;" />

如果租约的 DHCP IP 地址快过期了，客户端会向服务器发送 DHCP 请求报文：

- 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。
- 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址。

可以发现，DHCP 交互中，**全程都是使用 UDP 广播通信**。

> 咦，用的是广播，那如果 DHCP 服务器和客户端不是在同一个局域网内，路由器又不会转发广播包，那不是每个网络都要配一个 DHCP 服务器？

所以，为了解决这一问题，就出现了 **DHCP 中继代理**。有了 DHCP 中继代理以后，**对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。**

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031445056.jpeg" alt=" DHCP 中继代理" style="zoom: 67%;" />](https://camo.githubusercontent.com/9415fee9f5fa5ac4757e31d1536a65ece89e6c670e70176e78268fb1e270f687/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f49502f33372e6a7067)

- DHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以**单播**的形式发给 DHCP 服务器。
- 服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包广播给 DHCP 客户端。

因此，DHCP 服务器即使不在同一个链路上也可以实现统一分配和管理 IP 地址。





### NAT

**NAT**：一个私有 IP 地址转换成一个公有 IP 地址



可以把 IP 地址 + 端口号一起进行转换。

这样，就用一个全球 IP 地址就可以了，这种转换技术就叫**网络地址与端口转换 NAPT。**

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031448292.png" alt="image-20241203144818993" style="zoom:80%;" />



**NAT/NAPT 缺点：**

由于 NAT/NAPT 都依赖于自己的转换表，因此会有以下的问题：

- 外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。
- 转换表的生成与转换操作都会产生性能开销。
- 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。



**解决办法：**

**1、改用 IPv6**

**2、 NAT 穿透技术**：客户端主动从 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了。





### ICMP

ICMP 全称是 **Internet Control Message Protocol**，也就是**互联网控制报文协议**。

**确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。**

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031456227.png" alt="image-20241203145623942" style="zoom: 50%;" />





### IGMP

ICMP 跟 IGMP 是一点关系都没有的

**IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间**，如下图中的蓝色部分。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031457337.png" alt="image-20241203145732123" style="zoom:50%;" />

- IGMP 报文采用 IP 封装，IP 头部的协议号为 2，而且 TTL 字段值通常为 1，因为 IGMP 是工作在主机与连接的路由器之间。





## Ping

### Ping的工作原理

ICMP 包头的**类型**字段：

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031601721.png" alt="image-20241203160134399" style="zoom:50%;" />



相比原生的 ICMP，这里多了两个字段：

- **标识符**：用以区分是哪个应用程序发 ICMP 包，比如用进程 `PID` 作为标识符；
- **序号**：序列号从 `0` 开始，每发送一次新的回送请求就会加 `1`，可以用来确认网络包是否有丢失。

在**选项数据**中，`ping` 还会存放发送请求的时间值，来计算往返时间，说明路程的长短。

![image-20241203160201064](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031602269.png)



#### 差错报文类型

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031603322.png" alt="image-20241203160303054" style="zoom:50%;" />



#### ping —— 查询报文类型的使用

请求：

![image-20241203160338795](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031603193.png)

相应：

![image-20241203160407818](https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031604993.png)

 ping 这个程序是**使用了 ICMP 里面的 ECHO REQUEST（类型为 8）和 ECHO REPLY（类型为 0）**。



#### traceroute —— 差错报文类型的使用

##### 1、故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器

traceroute 的第一个作用就是**故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。**

traceroute 的参数指向某个**目的 IP 地址**：

```
traceroute 192.168.1.100
```



> 这个作用是如何工作的呢？

它的原理就是利用 IP 包的**生存期限** 从 `1` 开始按照顺序递增的同时发送 **UDP 包**，强制接收 **ICMP 超时消息**的一种方法。

比如，将 TTL 设置 为 `1`，则遇到第一个路由器，就牺牲了，接着返回 ICMP 差错报文网络包，类型是**时间超时**。

接下来将 TTL 设置为 `2`，第一个路由器过了，遇到第二个路由器也牺牲了，也同时返回了 ICMP 差错报文数据包，如此往复，直到到达目的主机。

这样的过程，traceroute 就可以拿到了所有的路由器 IP。

当然有的路由器根本就不会返回这个 ICMP，所以对于有的公网地址，是看不到中间经过的路由的。

> 发送方如何知道发出的 UDP 包是否到达了目的主机呢？

traceroute 在发送 `UDP` 包时，会填入一个**不可能的端口号**值作为 UDP 目标端口号（大于 `3000` ）。当目的主机，收到 UDP 包后，会返回 ICMP 差错报文消息，但这个差错报文消息的类型是「**端口不可达**」。

所以，**当差错报文类型是端口不可达时，说明发送方发出的 UDP 包到达了目的主机。**



##### 2、故意设置不分片，从而确定路径的 MTU

traceroute 还有一个作用是**故意设置不分片，从而确定路径的 MTU**。

> 这么做是为了什么？

这样做的目的是为了**路径 MTU 发现**。

因为有的时候我们并不知道路由器的 `MTU` 大小，以太网的数据链路上的 `MTU` 通常是 `1500` 字节，但是非以太网的 `MTU` 值就不一样了，所以我们要知道 `MTU` 的大小，从而控制发送的包大小。

[<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031605646.jpeg" alt="MTU 路径发现（UDP 的情况下）" style="zoom: 67%;" />](https://camo.githubusercontent.com/4a2743e766898bc6fe2a3a6a5b2ad12ba31ba37279d6a233161c7623499b3fac/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f70696e672f31382e6a7067)

它的工作原理如下：

首先在发送端主机发送 `IP` 数据报时，将 `IP` 包首部的**分片禁止标志位设置为 1**。根据这个标志位，途中的路由器不会对大数据包进行分片，而是将包丢弃。

随后，通过一个 ICMP 的不可达消息将**数据链路上 MTU 的值**一起给发送主机，不可达消息的类型为「**需要进行分片但设置了不分片位**」。

发送主机端每次收到 ICMP 差错报文时就**减少**包的大小，以此来定位一个合适的 `MTU` 值，以便能到达目标主机。



### 断网了还能Ping127.0.0.1吗？

- `127.0.0.1` 是**回环地址**。`localhost`是**域名**，但默认等于 `127.0.0.1`。
- `ping` 回环地址和 `ping` 本机地址，是一样的，走的是**lo0 "假网卡"**，都会经过网络层和数据链路层等逻辑，最后在快要出网卡前**狠狠拐了个弯**，将数据插入到一个**链表**后就**软中断**通知 **ksoftirqd** 来进行**收数据**的逻辑，**压根就不出网络**。所以断网了也能 `ping` 通回环地址。
- 如果服务器 `listen` 的是 `0.0.0.0`，那么此时用`127.0.0.1`和本机地址**都可以**访问到服务。



#### 回环地址

在 IPV4 下用的是 **ping 127.0.0.1** 命令。在 IPV6 下用的是 **ping6 ::1** 命令。



#### TCP 发数据和 ping 的区别

ping 应用的底层，用的是网络层的**ICMP 协议**。

*PS：下图中有一处画错了，右边是 tcp 数据，而不是 ping 数据，我偷懒就不重画了*。

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031621488.png" alt="image-20241203162122137" style="zoom: 50%;" />



#### 为什么断网了还能 ping 通 127.0.0.1

<img src="https://raw.githubusercontent.com/raosirui/Picture/main/markdown/202412031623827.png" alt="image-20241203162332593" style="zoom:50%;" />

当发现**目标 IP 是外网 IP**时，会从"真网卡"发出。

当发现**目标 IP 是回环地址**时，就会选择**本地网卡**。

本地网卡，其实就是个 **"** **假网卡** **"**，它不像"真网卡"那样有个`ring buffer`什么的，"假网卡"会把数据推到一个叫 `input_pkt_queue` 的 **链表** 中。这个链表，其实是所有网卡共享的，上面挂着发给本机的各种消息。消息被发送到这个链表后，会再触发一个**软中断**。

专门处理软中断的工具人 **"** **ksoftirqd** **"**（这是个**内核线程**），它在收到软中断后就会立马去链表里把消息取出，然后顺着数据链路层、网络层等层层往上传递最后给到应用程序。



ping 回环地址和**通过 TCP 等各种协议发送数据到回环地址**都是走这条路径。整条路径从发到收，都没有经过"真网卡"。**之所以 127.0.0.1 叫本地回环地址，可以理解为，消息发出到这个地址上的话，就不会出网络，在本机打个转就又回来了。** 所以断网，依然能 `ping` 通 `127.0.0.1`。



#### **ping 回环地址和 ping 本机地址ip没有区别**。



#### 127.0.0.1 和 localhost 以及 0.0.0.0 有区别吗

**localhost是域名，通过DNS解析为127.0.0.1。**

执行 **ping 0.0.0.0，是会失败**的，因为它在`IPV4`中表示的是无效的**目标地址**。

如果 `listen` 的是本机的 `0.0.0.0` , 那么它表示本机上的**所有 IPV4 地址**。























# 五、网络接口层
